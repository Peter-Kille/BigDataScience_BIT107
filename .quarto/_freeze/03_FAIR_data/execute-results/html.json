{
  "hash": "7aa284d8d14fb007205ef59edb63aa91",
  "result": {
    "markdown": "---\ntitle-block-style: default\ntitle-block-banner: darkred\ntitle-block-banner-color: white\ntitle: \"FAIR Data\"\nsubtitle: \"Data Curation and repositories\"\nauthor: \"Prof. Peter Kille\"\ndate: today\naffiliation: \"Cardiff University\"\n---\n\n\n<body style=\"background-color:gray99;\">\n\n\n\n\n\n![](Images/logo.jpg){width=\"10%\"}\n\n# FAIR data sharing\n\nFAIR Data Principles\n\n-   Findable\n\n-   Accessibility\n\n-   Interoperability\n\n-   reusability\n\nReview detailed Opperational implications as articulated by (GO FAIR)[<https://www.go-fair.org/fair-principles/>]\n\nAlso consider Tim Berners-Less (5\\* deployment Scheme for open Data)[<https://5stardata.info/en/>]\n\n![alt text](Images/5star-data.png) Figure 1.\n5\\* data\n\nA widely used system for data sharing is the assignment of DOIs (Digital Object Identifier) - The DOI scheme is coordinated by a non-for International DOI Foundation (IDF)[<https://www.doi.org/index.html>] which manages a body of registration agencies which need to comply is a ISO accredited procedures.\nAll Journals and most databases providers can assign DOIs - once you have a DOI it measn your data is web accessible.\n\n::: {#hello .greeting .message style=\"color: red;\"}\nWorkshop activity:\n\n***What FAIR data principles are address but obtaining a DOI***\n:::\n\n# Data sharing platforms\n\n## **Guide to contributing to NCBI SRA**\n\nAre you looking to make your science more reproducible and transparent by making your data public?\nOr do you need to upload your data somewhere before your manuscript can be published?\nThe NCBI Sequence Reach Archive (SRA) is a public searchable platform where genetic data and associated metadata may be uploaded, downloaded and reused.\n\n### **Getting started**:\n\nBefore beginning, it is helpful to read through several NCBI pages to understand the necessary data that is required for a successful upload.\nA good starting point is [here](https://www.ncbi.nlm.nih.gov/sra/docs/submitportal/).\nUnderstanding NCBI's data hierarchy will also be helpful for understanding how your data should be submitted.\n\n####A summary of NCBI prefixes####\n\n| Prefix | Accession Name | NCBI Definition                                                                                                                                                                                                            |                                    Example                                     |\n|-----------|-----------|----------------------------------------|:---------:|\n| PRJNA  | BioProject     | The goal of your research effort                                                                                                                                                                                           |      [PRJNA477007](https://www.ncbi.nlm.nih.gov/bioproject/PRJNA477007/)       |\n| SRP    | Study          | An object that contains project metadata describing sequencing study or project                                                                                                                                            | [SRP150953](https://trace.ncbi.nlm.nih.gov/Traces/sra/sra.cgi?study=SRP150953) |\n| SAMN   | Sample         | An object that contains metadata describing the physical sample upon which a sequencing experiment was performed                                                                                                           |      [SAMN09463455](https://www.ncbi.nlm.nih.gov//biosample/SAMN09463455)      |\n| SRX    | Experiment     | An object containing metadata describing the library, platform selection and processing parameters involved in a sequencing experiment                                                                                     |      [SRX7621456](https://www.ncbi.nlm.nih.gov/sra/SRX7621456%5Baccn%5D)       |\n| SRR    | Run            | An object containing actual sequencing data for a sequencing experiment. Experiments may contain multiple runs if multiple sequencing instrument runs were needed, but preferable data structure is one run per experiment |   [SRR10954732](https://trace.ncbi.nlm.nih.gov/Traces/sra/?run=SRR10954732)    |\n\n### **Submitting**:\n\n**Log in on to the [SRA Submission Portal Wizard](https://submit.ncbi.nlm.nih.gov/subs/sra/)**\n\n**Create new submission** by clicking on the 'New Submission' button.\nYour submission will receive a temporary SUB# ID, and you can use this to contact SRA staff if you have issues.\n\n#####Follow steps (you can leave at any step and return to it later).\nThe Submission Portal will check to make sure everything is okay after each step and your position will be displayed on the progress bar.\n\n![alt text](https://www.ncbi.nlm.nih.gov/core/assets/sra/images/sra-8-steps.png) Figure 1.\nNCBI SRA submission progress bar\n\n**1. Submitter information**\n\nYou will be asked for your contact information and affiliations.\nYou can also create a Group, which will allow your collaborators to read, modify, submit and delete your submissions.\n\n**2. General information**\n\nYou will be asked if you already registered your project and samples.\nSelect yes or no.\nIf yes, enter the accession number for your existing BioProject and you will be redirected to Step #6.\nIf no, the Wizard will ask you to create them.\nSelect the release date for your data.\nThe default is immediately.\n\n**3. Project information**\n\nEnter information about your project, including title, a description and grant information.\n\n**4. BioSample type**\n\nSelect the best description for your data.\nA Pinsky Lab example would be 'Model organism or animal sample'.\n\n**5. BioSample attributes**\n\nYou will be asked to provide information about your samples.\nYou can either enter it directly into the built-in editor, or download a BioSamples template, fill it out and upload it.\n\nEnter each sample as a separate line and follow the directions on the template with regards to each of the colored data columns to ensure all necessary data have been included.\n\nA complete BioSamples template can be viewed [here](Images/SRA-submission-master/PADE_NCBI_biosamples.xlsx).\n\n**6. SRA metadata**\n\nIf you are entering metadata for new BioSamples, you may either enter the metadata using the built-in editor, or you may download a SRA metadata template, fill it out and upload it.\nFollow the instructions on the template to ensure all required information about sequencing methodology is included.\nAn example of a SRA metadata template for new BioSamples may be viewed [here](https://github.com/pinskylab/SRA-submission/blob/master/SRA_metadata_PADE.xlsx).\n\nIf you have previously uploaded SRA metadata, download and complete the SRA metadata template.\nYou must make sure that you include the BioSample accession number so that your new sequences are correctly linked to your existing BioSamples.\nAn easy way to obtain these is to navigate to your previous submission within the submission portal and then to Download the attributes file with BioSample accessions (Figure 2).\n\n![alt text](Images/SRA-submission-master/biosample_accessions.png)\n\nFigure 2.\nWhere to download a file with BioSample accession numbers for previously submitted samples.\n\n**7. Files**\n\nNCBI SRA accepts different file types.\nThe Pinsky Lab aims to contribute FASTQ and BAM files for each sequenced individual, plus the reference that reads are aligned to.\nMore information about file types may be found [here](https://www.ncbi.nlm.nih.gov/sra/docs/submitformats/).\nThe file names need to be the same as those that you specified in the SRA Metadata.\n\nAs genomic data are large, there are several ways to transfer your sequence data to the NCBI SRA. Within this section of the Submission Portal, NCBI offers several ways to transfer your data: HTTP/Aspera Connect Plugin, FTP/Aspera Command Line or Amazon S3.\nIf your data are less than 10 GB or you have fewer than 300 individuals, you can try to drag files directly into the Submission Portal, which will upload via HTTP.\nIf your data are larger, select `Request preload folder` button.\nIf you select the method you would like to use, some brief instructions will appear.\nHere, we will discuss various FTP options in more detail.\nNote that the time it takes to transfer your data will depend on the size of your data (often hours to days).\n\n**FTP using the command line**\n\n1.  Create a single directory with all the files you want to upload.\n2.  Ensure you have FTP. You may need to install if not.\n3.  Navigate to the directory all the files you want to upload are.\n4.  Establish a FTP connection by typing `ftp -i`.\n5.  Next, type `open ftp-private.ncbi.nlm.nih.gov`.\n6.  Provide your username this is listed in the Submission Portal, likely `subftp`.\n7.  Provide the password listed in the Submission Portal.\n8.  Navigate to your account folder listed in the Submission Portal: `cd uploads/your_account_folder_name`\n9.  Create a subfolder. You must do this or you will not be able to see your files in the preload option: `mkdir new_folder_name`\n10. Navigate into the target folder: `cd new_folder_name`\n11. Copy your files into the target folder: `mput *`\n12. Go back to the Submission Portal and select the folder to upload. It takes at least 10 minutes for transferred files to appear in the preload option.\n13. To exit the FTP window, type `bye`.\n\n**FTP using third-party software (Fetch, for example)**\n\n1.  Open a Fetch window and connect to the NCBI server by typing in the hostname, your username and password, and direct Fetch to your `new_folder_name` within `your_account_folder_name` (Figure 3).\n2.  Open another Fetch window and connect to the location of your data.\n3.  Highlight the files you want to transfer and drag into the Fetch window that is connected to the NCBI server. This will copy your files from your server to the NCBI server.\n4.  Go back to the Submission Portal and select the folder to upload. It takes at least 10 minutes for transferred files to appear in the preload option.\n\n![alt text](Images/SRA-submission-master/fetch.png) Figure 3.\nScreenshot showing how to connect to the NCBI server using Fetch\n\n**8. Review & submit**\n\nThe Submission Portal will check to make sure all your sequencing files have correctly transferred.\nIt will also check to make sure that you have uploaded sequence data for all listed BioSamples.\nReview all the information before completing the submission.\nIf an error arises during processing, you'll receive an email asking you to contact SRA staff.\n\n### **Troubleshooting**:\n\nIf you run into trouble, there is a [SRA Submission Portal Troubleshooting Guide](https://www.ncbi.nlm.nih.gov/sra/docs/submitspfiles), or email SRA staff at [sra\\@ncbi.nlm.nih.gov](sra@ncbi.nlm.nih.gov)\n\n::: {.greeting .message style=\"color: red;\"}\n## Review SRA submission process by reviewing submission SRX8525144\n\nIdentify the following data about this submission:\n\n-   Author\n\n-   Organism (full taxonomy)\n\n-   Sequencing platform / type\n\n-   Biomaterial, Bioproject\n\n-   Publication and aim of work\n:::\n\n## Creating a Zenodo Account\n\n***Step 1. Signup*** To create an account with Zenodo click on the signup tab at there home page `https://zenodo.org/`.\n\n![zenodo signup page](Images/Zendo_signup.png)\n\n***Step 2. Link to Github (or ORCID)*** You will be provided with options to link your submission to either your ORCID account or your Github account.\nIf you are a academic linking to you ORCID account has the advantage that it tracks your Zenodo submissions to your ORCID profile so people can immediately view your public accessions.\nFor today's session I suggest you link the account to your github account created earlier.\n\n![Link to Github](Images/Zendo_signup_withgit.png)\n\n***Step 3. Zenodo Authorization form*** Zenodo needs you to agree to various data sharing protocols - review and accept if you are happy to do so.\n\n![Zenodo Authortization](Images/Zendo_Authortize.png) ***Step 4. Data Upload*** I suggest you upload your ICA assigned sequences.\n\n![Upload Page](Images/Zendo_upload.png)\n\n***Step 5. Zenodo Big Data Biology Master Community*** I have created a community that you can associated your data with so we can see the class submissions.\n\n![Cardiff University - Big Data Biology Masters](Images/Zendo_community_Cu-bdbm.png)\n\n***Step 6. Submission Pages*** Here's is a minimal metadata need to support the submission.\nI suggest you keep the submission as ***closed access*** submission as you will uploading non-primary data.\n\n![Subission Page 1](Images/Zendo_upload_Page1.png)\n\n![Subission Page 2](Images/Zendo_upload_Page2.png)\n\n![Subission Page 3](Images/Zendo_upload_Page3.png)\n\n***Step 7. Review Submission*** Review the submission -\n\n![Review Submission](Images/Zendo_Uploaded.png)\n\n::: {.greeting .message style=\"color: red;\"}\n### Zenodo\n\n-   Create an account\n-   Use a dataset to create a private repository\n-   Link repository to your github page\n-   Create a private submission linked to cu-bdbm community\n:::\n\n# Reproducible Informatics -- beyond git\n\n## Linux Containers - from Linux primitives to container run-time software\n\nLinux containers are a method of isolating running process from the host system.\nContainers will provide:\n\n-   filesystem isolation\n-   process isolation\n-   resource limitations, and\n-   network isolation (not discussed in this tutorial)\n\nWe will discover exactly what these mean as we progress through the tutorial.\n\n## containers vs virtual machines\n\nAny introductory course on containers will almost always start with a comparison of containers vs. virtual machines.\n(I am unsure how useful this actually is to students undertaking their first course on Linux, they may well meet containers before even coming across Virtual Machines).\nAssuming you're aware of both, we provide a brief comparison now:\n\nIn effect, virtual machines virtualise hardware, and containers will virtualise the Linux kernel.\nVirtual machines will run their own Linux kernel on top of virtualised hardware; containers will share the host's kernel.\nThis means any processes in a virtual machine will often need to pass through two separate kernels to perform a given task; conversely, any interaction with hardware from processes within a container, need only deal with the single host kernel.\nThis often means that container processes have little overhead, and processes are handled at host-native speeds.\nWhereas virtual machine processes have more overhead and will often suffer in performance.\n\n## Container Runtimes -- docker/singularity/podman\n\nThe above tutorial built up a container using linux primitives alone.\nThis is obviously a rather cumbersome approach to creating containers and container images.\nThe following set of tools are some of the, perhaps, more well-known container runtime engines and container image and management software.\n\n-   docker\\*\n-   podman\\*\n-   containerd\n-   systemd-nspawn\n-   charliecloud\\*\n-   singularity\\*\n\nThese container runtime engines are (mostly) command-line tools that make creating, updating, packaging, distributing, and running containers significantly easier than using the Linux primitives we met earlier.\nThis allowed them to become very popular with system administrators, and also program developers to distribute their software.\nThese tools, at their core, do exactly what we did with the Linux primitives, but abstract many of the complexities away from managing cgroups, namespaces, and chroot, but in a more convenient way.\n\nThose container run-time engines marked with the '\\*', above, are the container run-time engines that computational scientists are most likely to come across.\nDocker/Podman have very similar features to one another, and are best suited to personal desktops/laptops (i.e. single tenancy systems).\nSingularity/Charliecloud are also very similar to one another, and will often be available to researchers on multi-tenancy HPC clusters.\n\nThe reason that Docker/Podman\\*\\* are not suitable to multi-tenancy systems is that by default containers run as the root user.\nIf you launch a container with docker, unless you specify a specific user, you're going to run that container as the root user.\nAnd this is the same root user inside the container as the root on the host (much the same as in our Linux primitives tutorial above).\nIn addition, when providing a non-privileged user access to the docker runtime, that user can easily get access to the host's root account with just a few Docker commands - an obvious security risk in multi-tenancy environments.\n\n\\*\\* Podman in fact does have some mechanism to not run as the host's root inside the container, but it's still not often found on multi-tenancy servers.\n\nConversely, the container run-time engines of Singularity and Charliecloud are safe to run in multi-tenancy environments.\nThese run-time engines use a more recent kernel feature of *User Namespaces*.\nThese are like the namespaces we met in the above *chroot* tutorial, except that a \"*root*\" user inside the container is mapped to a non-privileged user on the host.\nThis is all handled by the Linux kernel - so no new security boundary exists (we've already accepted the Linux kernel as safe).\n\n## Container repositories\n\n-   (Docker)[<https://hub.docker.com/>]\n\n-   (Singularity)[sylabs.io]\n\n-   Podman -- Search within application - podman search <search_term>\n\n-   (Charliecloud)[<https://github.com/hpc/charliecloud>]\n\n::: {.greeting .message style=\"color: red;\"}\nUse Docker hub to identify a containers that would support fastqc, trimmomatic (or fastp) and multiqc.\n\n-   How would you judge a container is valid and 'safe' to use\n\n-   Can you identify a container that has all the of the programs\n:::\n\n# Using Containers\n\n## Pulling and using a Container in an interactive job\n\nRunning interactive *Singularity* containers is simple:\n\n1.  Pull image (or use an existing one)\n2.  Create and enter an interactive slurm job\n3.  Run and enter the Singularity container\n\n(The final two steps could also be combined into one command.)\n\n## Example of pulling down and running an Ubuntu image\n\n\n::: {.cell}\n\n```{.bash .cell-code}\n## Enter interactive node on defq\nsrun -c 4 --mem=8G -p defq --pty bash\n\n## Load latest singularity module\nmodule load singularity/3.8.7\n\n##make and enter a directory for your containers within your mydata directory\ncd /mnt/clusters/sponsa/data/$USER/\nmkdir singularity\ncd singularity/\n\n##Create cache and point the singularity cache directory\nmkdir cache\nexport SINGULARITY_TMPDIR=/mnt/clusters/sponsa/data/$USER/singularity/cache/\nexport SINGULARITY_CACHEDIR=/mnt/clusters/sponsa/data/$USER/singularity/cache\n\n## Create and enter a working folder\nmkdir working\ncd working/\n\n\n## Pull ubuntu version 20.04 from Docker Hub and store as .sif image\nsingularity pull ubuntu.sif docker://ubuntu:20.04\n\n# Run singularity container\n# --contain is optional but will ensure $HOME is not auto mounted\nsingularity run --contain ubuntu.sif\n\n# You should now find yourself within the container\nSingularity>\n\n# Try checking the operating system by running\ncat /etc/os-release\n# If working this should be Ubuntu if not working then RockyLinux (iago OS)\n\n# To exit container\nexit\n```\n:::\n\n\n### Security warning\n\nThe **\\--contain** option when running a container is considered optional in singularity but **essential** by the BiocomputingHub.\nBy default Singularity will try to auto-mount your \\$HOME folder into the container.\nWhile this may not seem like an issue, if you are pulling down an unknown Docker Hub image (or using a .sif file created by someone else) this potentially could be compromised in some form.\nFor example if it has a runscript to delete all files and folders on the mounted home drive then it could potentially wipe your home drive (or anything else you have mounted).\nSingularity runs with the same permission inside the container as outside the container for security, no critical protected files will be removed if you do not have permission to delete them.\n\n### What next ?\n\nThe ubuntu image is pretty useless by itself but serves as a good demo, there are however multiple pre-made images on Docker Hub that can be downloaded and used in Singularity (<https://hub.docker.com/>).\nSomething more useful would be an up to date python image, such as python:3.9.12-buster\n\nFollow the previous guide up to the step where you pull down the image...\n\n\n::: {.cell}\n\n```{.bash .cell-code}\n# Pull Python version 3.9.12 from Docker Hub and store as .sif image\nsingularity pull python3.9.12.sif docker://python:3.9.12-buster\n\n# Run the container in singularity\nsingularity run --contain python3.9.12.sif\n\nPython 3.9.12 (main, Apr 20 2022, 18:47:18) \n[GCC 8.3.0] on linux\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\n>>> \n```\n:::\n\n\nYou will notice that unlike the ubuntu image this launches straight into the python application.\nThis is caused by the singularity runscript that is set within the container.\nTo check what the runscript will do on run, you can run this command outside of the container :\n\n\n::: {.cell}\n\n```{.bash .cell-code}\nsingularity inspect -r python3.9.12.sif\n\n# At the top of the resulting text you will see something like:\n#!/bin/sh\nOCI_ENTRYPOINT=''\nOCI_CMD='\"python3\"'\nCMDLINE_ARGS=\"\"\n```\n:::\n\n\nThe OCI_CMD is the command running inside the container on launch, for the python container this is launching python3.\nIf you want to launch the container without auto launching python3 (without the runscript) then you can use singularity shell, using the python container as an example:\n\n\n::: {.cell}\n\n```{.bash .cell-code}\nsingularity shell --contain python3.9.12.sif \nSingularity> \n```\n:::\n\n\n### Running scripts and binding folders to container\n\nAs well as run and shell the other most useful command is **exec**, this allows you to execute a command when the container is launched.\n\nFor example to run a simple Python script.\n\nMake a demo python script called example.py with the following contents.\n\n\n::: {.cell}\n\n```{.bash .cell-code}\n#!/usr/bin/python3\nprint('This is a demo python script')\n```\n:::\n\n\nMake it executable\n\n\n::: {.cell}\n\n```{.bash .cell-code}\nchmod +x example.py\n```\n:::\n\n\nTo be able to run the example.py script within the container you have to make the folder location accessible within the container.\nThe easiest way to do this is to bind (mount/attach) the folder to a specified location within the container using the **-B** option.\n\nAssume that example.py is located at `/mnt/clusters/sponsa/data/$USER/script`\n\n\n::: {.cell}\n\n```{.bash .cell-code}\nsingularity exec --contain -B /mnt/clusters/sponsa/data/$USER/script:/mnt/clusters/sponsa/data/$USER/script python3.9.12.sif \\\npython /mnt/clusters/sponsa/data/$USER/script/example.py\n> This is a demo python script\n```\n:::\n\n\nThis command is mounting the `/mnt/clusters/sponsa/data/$USER/script` folder to the same location within the `python.sif` container, then executing the python command with the example.py script.\n\nThe output is passed back outside the container and the container is automatically killed as it has no other tasks to perform.\n\nYou do not need to bind to the same location as the folder (/mnt/clusters/sponsa/data/\\$USER/script...) but it's pretty confusing if you don't !!\n\n\n::: {.cell}\n\n```{.bash .cell-code}\nsingularity exec --contain -B /mnt/clusters/sponsa/data/$USER/script:/bind python3.9.12.sif python /bind/example.py\n> This is a demo python script\n```\n:::\n\n\n## Using containers in Slurm scripts\n\nThis is a workflow of how to safely pull and convert an existing docker image from Docker Hub.\nDocker Hub is a cloud based repository used mainly for storing and distributing container images.\n\nOne of the benefits of Singularity is the ability to convert Docker images into Singularity images.\n\nFor this workflow we will be pulling and converting a container image for fastqc, this is a popular program used for quality assesses NGS data.\n\n<br><strong>Not all Docker container images will work in Singularity, Docker requires root access to run.<br>Singularity on gomphus runs without any root access so the container images are immutable.<br></strong> <br>\n\n### Security : Finding a safe image to download\n\nAny docker user can upload to Docker Hub, please do not automatically assume all of these images are safe and working correctly !\n\nTo find a safe image to download then treat Docker Hub the same as downloading software from any internet site.\n\nSearching for fastqc on Docker Hub (<https://hub.docker.com/search?q=fastqc>) brings up lots of container images.\nLook for those images from reliable sources (such as the application creator), updated relatively recently, with a large number of downloads and if possible stars (these are given by previous users).\n\n(Often official image are listed on the github sites of the software - this is not the case for fastqc as it is predates container use)\n\n<br> \\### Pulling the image\n\nRun the usual setup procedure to create a singularity environment, it's important to set the cachedir as some container images will be bigger than your %HOME space.\n\n\n::: {.cell}\n\n```{.bash .cell-code}\n# Enter interactive node on defq (epyc could also be used)\nsrun -c 4 --mem=8G -p defq --pty bash\n\n# Load latest singularity module\nmodule load singularity/3.8.7\n\n# Point the singularity cache directory\nexport SINGULARITY_TMPDIR=/mnt/clusters/sponsa/data/$USER/singularity/cache/\nexport SINGULARITY_CACHEDIR=/mnt/clusters/sponsa/data/$USER/singularity/cache\n\n# Enter working folder\ncd /mnt/clusters/sponsa/data/$USER/singularity/\n```\n:::\n\n\nPull the container image with the following command.\nTo ensure reproducibly in some form it's better to use the tag specifying the version number in the pull command.\nAlso name your sif file with a similar tag for future reference.\n\n\n::: {.cell}\n\n```{.bash .cell-code}\nsingularity pull fastqc.sif docker://staphb/fastqc\n```\n:::\n\n\nThis will start downloading the image layers and converting to .sif.\nThe process can take a while so be patient, when nearly finished you will see 'Creating SIF file...'\n\n\n::: {.cell}\n\n```{.bash .cell-code}\nINFO:    Converting OCI blobs to SIF format\nINFO:    Starting build...\nGetting image source signatures\nCopying blob 7595c8c21622 done  \nCopying blob d13af8ca898f done  \nCopying blob 70799171ddba done\n.\n.\n.\nINFO:    Creating SIF file...\n```\n:::\n\n\n<br>\n\n### Using the sif image\n\n**Do not run the sif image, you will not be able to find out what it does until it's too late**,start by inspecting the runscript (what it will do when run) inside the image using:\n\n\n::: {.cell}\n\n```{.bash .cell-code}\nsingularity inspect -r fastqc.sif\n```\n:::\n\n\nThis shows the runscript as running **OCI_CMD='\"/bin/bash\"'**, so will simply run a bash prompt inside the container which is a good start.\n\nNow try entering the container, I would advise ignoring the runscript option and using 'singularity shell' to open a shell inside the container.\nRemember to also use **--contain**, this will isolate the container and prevent it from mounting your \\$HOME folder which would be a big security risk on unknown containers.\n\n\n::: {.cell}\n\n```{.bash .cell-code}\nsingularity shell --contain fastqc.sif\n```\n:::\n\n\nThis should put you inside the container with a Singularity\\> prompt.\nRun some commands to verify the container is what you expect it to be.\nFor example checking for operating system version and in this case checking the Trinity version matches what was specified on the docker tags.\nExit the container when finished.\n\n\n::: {.cell}\n\n```{.bash .cell-code}\n# OS version\nSingularity> cat /etc/os-release \nNAME=\"Ubuntu\"\nVERSION=\"16.04.7 LTS (Xenial Xerus)\"\nID=ubuntu\nID_LIKE=debian\nPRETTY_NAME=\"Ubuntu 16.04.7 LTS\"\nVERSION_ID=\"16.04\"\nHOME_URL=\"http://www.ubuntu.com/\"\nSUPPORT_URL=\"http://help.ubuntu.com/\"\nBUG_REPORT_URL=\"http://bugs.launchpad.net/ubuntu/\"\nVERSION_CODENAME=xenial\nUBUNTU_CODENAME=xenial\n\n# Trinity version\nSingularity> fastqc -v\nperl: warning: Setting locale failed.\nperl: warning: Please check that your locale settings:\n        LANGUAGE = (unset),\n        LC_ALL = (unset),\n        LANG = \"en_GB.UTF-8\"\n    are supported and installed on your system.\nperl: warning: Falling back to the standard locale (\"C\").\nFastQC v0.11.9\n\n\n# exit container\nSingularity> exit\n```\n:::\n\n\n<br>\n\n### Where to store the container\n\nOnce verified you can move the fastqc.sif anywhere you need.\nIf storing the containers for any period of time just remember that any security issues or bugs will also remain in the container, they are essentially locked in time.\n\n<br>\n\n### Reproducibility\n\nIt's important to document how the container was pulled or built, that way it can be re-created or updated if required again in the future.\nAs a researcher you will also want to aid reproducibility of your workflow by at least recording any relevant versions of code or container-images.\nSo you may want to rename this container with its version.\n\n\n::: {.cell}\n\n```{.bash .cell-code}\nmv fastqc.sif fastqcv0.11.9.sif\n```\n:::\n\n\n<br>\n\n### Interactive mode\n\nLet's use the fastqc.sif image to run interactively, including binding a directory to run some tests.\nWe will be using sample_data from Session5 RNAseq-Processing `/mnt/clusters/sponsa/data/classdata/Bioinformatics/Session5/RNAseq-Processing/fastq/SRR*.fastq`\n\nCreate an interactive node on the defq partition.\n\n\n::: {.cell}\n\n```{.bash .cell-code}\nsrun -c 4 --mem=8G -p defq --pty bash\n\n# load singularity module\nmodule load singularity/3.8.7\n\nmkdir /mnt/clusters/sponsa/data/$USER/singularity/test_data/\n\ncd /mnt/clusters/sponsa/data/$USER/singularity/test_data/\n\ncp /mnt/clusters/sponsa/data/classdata/Bioinformatics/Session5/RNAseq-Processing/fastq/SRR*.fastq .\n```\n:::\n\n\nTo use the test data we need to make that folder accessible inside the container.\nWe could bind the complete `/mnt/clusters/sponsa/data/$USER/` folder but it's more secure to only bind the folder(s) you require inside the container.\nYou can specify where the folder is mounted inside the container but I will use the same folder location as outside the container to make it easier to remember.\n\n<br><strong>As we are using --contain to protect the home folder it's a good idea to change to a working directory where you have full write access.\nUsing --pwd is a simple way of setting the default folder on container launch<br></strong> <br>\n\n\n::: {.cell}\n\n```{.bash .cell-code}\n# use --bind or -B to bind folder\n# use --contain to prevent mounting of home folder\nsingularity shell --contain --bind /mnt/clusters/sponsa/data/$USER/singularity/test_data/:/mnt/clusters/sponsa/data/$USER/singularity/test_data/ --pwd \\\n/mnt/clusters/sponsa/data/$USER/singularity/test_data/  /mnt/clusters/sponsa/data/${USER}/singularity/working/fastqcv0.11.9.sif\n\n# You should now see the singularity> prompt inside the container\n\n# test if sample data is attached correctly\nsingularity> ls /mnt/clusters/sponsa/data/$USER/singularity/test_data/\n```\n:::\n\n\nOnce inside the container you can run standard trinity commands, you may need to specify output locations.\nIf the output tries to write to an area outside of your mounted/bound folder it will either fail due to lack of permissions (images are read only) or it will appear to write but dissapear when the container is exited.\n\n\n::: {.cell}\n\n```{.bash .cell-code}\n# run a standard fastqc command within container\nfastqc -t 4 SRR*\n```\n:::\n\n\n<br>\n\n### Slurm\n\nOnce confident that the container image does the job you require you can wrap it into a slurm script to automate the process.\n\n\n::: {.cell}\n\n```{.bash .cell-code}\n#!/bin/bash\n#SBATCH --partition=defq       # the requested queue\n#SBATCH --nodes=1              # number of nodes to use\n#SBATCH --tasks-per-node=1     #\n#SBATCH --cpus-per-task=4      #   \n#SBATCH --mem=8G     # in megabytes, unless unit explicitly stated\n#SBATCH --error=%J.err         # redirect stderr to this file\n#SBATCH --output=%J.out        # redirect stdout to this file\n##SBATCH --mail-user=[insert email address]@Cardiff.ac.uk  # email address used for event notification\n##SBATCH --mail-type=all                                   # email on job start, failure and end\n\n\necho \"Some Usable Environment Variables:\"\necho \"=================================\"\necho \"hostname=$(hostname)\"\necho \\$SLURM_JOB_ID=${SLURM_JOB_ID}\necho \\$SLURM_NTASKS=${SLURM_NTASKS}\necho \\$SLURM_NTASKS_PER_NODE=${SLURM_NTASKS_PER_NODE}\necho \\$SLURM_CPUS_PER_TASK=${SLURM_CPUS_PER_TASK}\necho \\$SLURM_JOB_CPUS_PER_NODE=${SLURM_JOB_CPUS_PER_NODE}\necho \\$SLURM_MEM_PER_CPU=${SLURM_MEM_PER_CPU}\n\n# Write jobscript to output file (good for reproducability)\ncat $0\n```\n:::\n\n\nLoad the singularity module and then set the location of the .sif container image.\nThe TOTAL_RAM variable simply converts \\${SLURM_MEM_PER_NODE} back into GB, trinity can only use GB and slurm tends to convert GB to MB.\nWORKINGFOLDER in this case is the location of the test data and what we will also use as default folder within the container, as it will be set to our external bound folder it will have full read&write access.\nThe BINDS variable will container any folders you wish to bind into the container, you can specify multiple folders seperated by ','.\nYou need to specify the iago location of the folder and then the mount point within the container.\n\n\n::: {.cell}\n\n```{.bash .cell-code}\n# load singularity module\nmodule load singularity/3.8.7\n\n# set singularity image\nSINGIMAGEDIR=/mnt/clusters/sponsa/data/${USER}/singularity/working/\nSINGIMAGENAME=fastqcv0.11.9.sif\n\n# Set working directory \nWORKINGFOLDER=/mnt/clusters/sponsa/data/$USER/singularity/test_data/\n\n# set folders to bind into container\nexport BINDS=\"${BINDS},${WORKINGFOLDER}:${WORKINGFOLDER}\"\n```\n:::\n\n\nTo be able to run a Trinity script inside the container the script needs to be in a location that is accessible within the container, the easiest folder in this case is the WORKINGFOLDER.\nYou can either generate a bash script (trinity_source_commands.sh) as part of the sbatch script or link to an existing script.\nAdding the commands to the sbatch script is better for reproducability, having a seperate script is more likely to be forgotten in a few months but the choice is yours.\n\nThe Trinity commands are pretty standard, but we make use of the WORKINGFOLDER variable and slurm environment variables to declare RAM and CPU.\nI like to echo the TOTAL_RAM AND CPU to the output file (JOBID.out) to check the conversion worked correctly and the CPU total is also matching, obviously not essential.\n\n\n::: {.cell}\n\n```{.bash .cell-code}\n############# SOURCE COMMANDS ##################################\ncat >${WORKINGFOLDER}/fastqc_source_commands.sh <<EOF\nfastqc -t ${SLURM_CPUS_PER_TASK} SRR*\n\necho TOTAL_RAM=${TOTAL_RAM}\necho CPU=${SLURM_CPUS_PER_TASK}\n\nEOF\n################ END OF SOURCE COMMANDS ######################\n```\n:::\n\n\nThis is the magic command that sets up the singularity container environment, binds requested drives, sets the working directory and then executes the bash script inside of the container.\n\n\n::: {.cell}\n\n```{.bash .cell-code}\nsingularity exec --contain --bind ${BINDS} --pwd ${WORKINGFOLDER} ${SINGIMAGEDIR}/${SINGIMAGENAME} bash ${WORKINGFOLDER}/fastqc_source_commands.sh\n```\n:::\n\n\nThis is the same as all slurm jobs where a JOBID will be created and queued within the slurm queue, on completion of the script the container and job will close.\nThe slurm logs .out and .err will contain the job details so please check on completion.\n\n# Building Containers from Scratch - Extension work - only for greeks\n\n## Linux *chroot* Jails\n\nJails are similar to containers (although cannot quite be classed as a container because by themselves they do not fit the isolation criteria).\nNonetheless, we will start our journey with jails, because all the tools needed to create jails are usually already available by default on any Linux system.\n\nJails have been available to Linux since the 1980's (long before containers were introduced to the Linux kernel, around 2006).\nJails provide a method of isolating the filesystem, so that the jail cannot see the host's filesystem.\nDuring this tutorial we will further implement limitations on the jail, isolating various other aspects of the host system away from the jail, to the point where we convert our jail to a full-fledged container.\n\nFirst of all, we want to virtualise a linux system, so let's start by building up a typical linux filesystem - like the one listed above.\nDownload the Alpine minirootfs and unpack.\nAlpine is a well-known and (very) lightweight linux distribution.\n\n\n::: {.cell}\n\n```{.bash .cell-code}\nmkdir alpine && curl -L https://dl-cdn.alpinelinux.org/alpine/v3.16/releases/x86_64/alpine-minirootfs-3.16.2-x86_64.tar.gz   | tar xvzf - -C alpine\n#\n# for the purposes of this tutorial only: add a file to alpine, to help with navigation when switching between host and jail.\ntouch alpine/in_alpine\n#\n# change ownership to the alpine folder to root (recursively)\nsudo chown -R root:root alpine/\n```\n:::\n\n\nTake a look at the resulting *alpine* folder, and you should see something similar to the filesystem tree shown above.\n\n## filesystem isolation\n\nCreate and enter a chroot jail.\nThe following command will create a jail, and run the */bin/sh* process within that jail.\nYou can exit the chroot jail whenever you like by typing *exit* or *ctrl-d*.\n\n\n::: {.cell}\n\n```{.bash .cell-code}\nsudo chroot alpine /bin/sh -l\n```\n:::\n\n\nThis jail provides us with filesystem isolation.\nLook around the filesystem within the jail, and you will see no way out to the host filesystem.\n\n## process isolation\n\nHowever, this chroot jail does nothing about process-isolation, network-isolation, or resource-limitation.\nIn fact, probing for any information about any processes currently fails (even processes within the chroot jail itself).\nThis is because the */proc*, */sys*, and */dev* pseudo-filesystems have not yet been made available to the chroot jail, so therefore the jail has no route to probe the linux kernel.\nLet's fix that now, and mount the pseudo-filesystems.\n\n\n::: {.cell}\n\n```{.bash .cell-code}\n# we're still in the jail\nmount -t proc none /proc\nmount -t sysfs none /sys\nmount -t devtmpfs none /dev\n```\n:::\n\n\nNow we can prove that no process-isolation takes place.\nBecause the chroot jail now has access to the host kernel (because of our mounted /proc, /sys, and /dev), we can now probe the running processes from inside the chroot jail.\nRunning\n\n\n::: {.cell}\n\n```{.bash .cell-code}\ntop\n# press 'q' to exit when ready to do so\n```\n:::\n\n\nyou can see not only the running processes inside the chroot jail, but all processes running on the host system.\ni.e. there is no process isolation within this chroot jail.\n\n## resource limitation\n\nTo test our chrooot jails for resource limitation, we will create a chroot jail (with the mounted kernel folders), and install some stress-test software to see if there is any limitation to how many resources we can consume (answer: resources are not restrained in any way).\n\n\n::: {.cell}\n\n```{.bash .cell-code}\nsudo chroot alpine /bin/sh -l\n#\n# provide the chroot with access to the google dns service\necho 'nameserver 8.8.8.8 >/etc/resolv.conf\n#\n# install some software (apk is the alpine package manager)\napk add python3 python3-dev gcc linux-headers musl-dev bash\n```\n:::\n\n\nNow that some useful software is installed into our *chroot* image, exit and re-enter the *chroot* jail, this time with a slightly more useful *shell*.\n\n\n::: {.cell}\n\n```{.bash .cell-code}\n# ctrl-d to exit the chroot jail, then re-enter\nsudo chroot alpine /bin/bash -l\n```\n:::\n\n\nNow we're back inside the *chroot* jail, let's install our stress-test software:\n\n\n::: {.cell}\n\n```{.bash .cell-code}\npython3 -m venv /opt/pycont --clear --copies\n. /opt/pycont/bin/activate\npip install stress\n```\n:::\n\n\nNow let's stress out our *chroot* jail.\n\n\n::: {.cell}\n\n```{.bash .cell-code}\n# this commands will run $THREADS threads.\nTHREADS=16\nstress -c $THREADS\n```\n:::\n\n\nYou can check out the cpu usage from a terminal on the host machine.\nYou can choose any number of threads, you will find the only cpu-limit is that of the hardware of your host machine.\n\nSo, we have seen that chroot jails will isolate a filesystem, but does not limit resources, or isolate processes.\n\n## Limiting resources with cgroups\n\nIn order to limit processes to a certain amount of resource (CPU, RAM), one can use *cgroups* (Control Groups).\n*cgroups* is a Linux kernel feature that will allow the limitation of resources (CPU, RAM) available to a process.\nAnd because UNIX processes are hierarchical, children of the *cgroup*'d process are in the same cgroup and will contribute to the same limit.\n\nLet's set up a *cgroup* and attach our chroot jail to it.\n\n\n::: {.cell}\n\n```{.bash .cell-code}\nsudo cgcreate -a $USER -g memory,cpuset:alpine-jail\n```\n:::\n\n\nThis will set up a cgroup within the linux kernel, called *alpine-jail*, owned by the \\$USER that ran the command.\nWe can see the setup within the kernel */sys* folder:\n\n``` bash\nls -l /sys/fs/cgroup/*/alpine-jail  #* list the contents of multiple alpine-jail folders \n```\n\nLimit the resources available to this cgroup by making changes to the kernel data-structures:\n\n\n::: {.cell}\n\n```{.bash .cell-code}\n# Note, since the user $USER owns this data-structure, sudo access is not necessary\n# Limit RAM to 4GB\necho 2000000000 > /sys/fs/cgroup/memory/alpine-jail/memory.limit_in_bytes\n# Limit the cgroup to use the first 5 CPUs only\necho 0-4 > /sys/fs/cgroup/cpuset/alpine-jail/cpuset.cpus\n```\n:::\n\n\nNow we can create the chroot jail, this time running under our newly created cgroup.\n\n\n::: {.cell}\n\n```{.bash .cell-code}\nsudo cgexec -g memory,cpuset:alpine-jail  chroot alpine /bin/bash -l\n```\n:::\n\n\nWhile within the chroot jail, run the stress command and check out *top* from a host terminal.\n\n\n::: {.cell}\n\n```{.bash .cell-code}\n. opt/pycont/bin/activate\nstress -c 10\n```\n:::\n\n\nBecause we limited the cgroup to cpus 0-4 only, our chroot jail only has 5 cpus from the host available to it.\nBy running *stress* across 10 cpus, you should see that the process is limited, and 10 threads are being shared across 5 cpus, each thread running at approximately 50% cpu usage.\n\nOur chroot jail can now almost be classed as a container.\nAll that is left is for us to do is isolate processes.\n\n## Isolating processes with Namespaces\n\nOur next target for creating a full-fledged container, is to limit our virtual linux environment to have access to list and probe it's own processes only.\nThat is, the jail should not be able to see any information about any processes that were not spawned within that jail.\nUnsurprisingly, the Linux kernel has a feature to do exactly that.\nThese are called *Namespaces*.\nNamespaces allow us to hide processes from other processes.\nThere are many different types of Namespaces (process, network, mount, and more), and their description are beyond the scope of this tutorial.\nBut for our purposes, we will simply bundle up the relevant Namespaces into a single command.\nAnd the command we will now introduce, is called *unshare*.\n\n\n::: {.cell}\n\n```{.bash .cell-code}\nsudo unshare  --mount --uts --ipc --pid --fork --user --map-root-user chroot alpine /bin/bash\n```\n:::\n\n\nThe above unshare command will create a new namespace for the chroot alpine jail.\nThis namespace is a new environment that's isolated on the system with its own processes (PIDs), and mounts (volumes) etc.\n\nBy running the above Namespaced jail, we immediately enter the isolated environment.\nAnd since we have restricted mounts (check out the unshare arguments), we are not able to mount all the psuedo-filesystems as we did previously.\nHowever, just mounting the /proc filesystem will suffice:\n\n\n::: {.cell}\n\n```{.bash .cell-code}\nmount -t proc none /proc\n```\n:::\n\n\nNow, running the top command, we can see we have isolated processes - the only processes listed are those that have been spawned from within the jail/container.\nThat is, we are not able to see any information about processes on the host.\n\n\n::: {.cell}\n\n```{.bash .cell-code}\ntop\n```\n:::\n\n\nWe have now used the kernel feature *Namespaces* to protect the host processes from the container processes.\n\nNext, we will collate what we have learned, and form a command that will create a truly isolated container runtime, using linux primitives and kernel features alone.\n\n## Putting it all together\n\nHaving run through all our isolation techniques, the following command will create a container from using Linux primitives only.\n\n\n::: {.cell}\n\n```{.bash .cell-code}\n# assumes the cgroup has been cerated\nsudo  cgexec -g memory,cpuset:alpine-jail  \\\n  unshare  --mount --uts --ipc --pid --fork --user --map-root-user \\\n  chroot alpine /bin/bash\n# you may need to mount the /proc filesystem again\nmount -t proc none /proc\n```\n:::\n\n\nThe command may look a little complicated, but we have met all the components of this command separately throughout this tutorial: the *chroot* will isolate a filesystem; the *unshare* will isolate the processes; and the *cgexec* will limit the resources.\n\n## Cleaning up\n\nTo clean up the chroot jail, exit the jail, then unmount the pseudo-filesystems..\n\n\n::: {.cell}\n\n```{.bash .cell-code}\nbash sudo umount alpine/proc alpine/sys alpine/dev\n```\n:::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}