{"title":"HPC, Cloud Computing & Job Schedulers","markdown":{"yaml":{"title-block-style":"default","title-block-banner":"darkred","title-block-banner-color":"white","title":"HPC, Cloud Computing & Job Schedulers","subtitle":"High Performace Computing","author":"Prof. Peter Kille","date":"today","affiliation":"Cardiff University"},"headingText":"My HPC System","containsRefs":false,"markdown":"\n\n<body style=\"background-color:gray99;\">\n\n```{r include=FALSE}\nknitr::opts_chunk$set(eval = FALSE)\n```\n\n![](Images/logo.jpg){width=\"10%\"}\n\n\nAll HPC are slightly different and it is important to understand the specific system you are using. The current activities cover relate to the IT infrastructure provided to Big Data Masters student at Cardiff University session 2022-23. If you are not part of this class then you will need to request appropriate information about the system you have been given access to.\n\n## House Keeping\n\n### login to the server\n\nHPC system available to big data masters students:\n\nhost\n\n```{bash}\ngomphus.bios.cf.ac.uk\n```\n\nUser name `university username` Password `SSO Password` Port `22`\n\nWe suggest you use (MobaXterm)\\[<https://mobaxterm.mobatek.net/>\\] (PC) and terminal SSH (Mac) to access the server and MobaXtrem and (cyberduck)\\[<https://cyberduck.io/>\\] or (filezilla)\\[<https://filezilla-project.org/>\\] to allow secure file transfer (sftp) between server and local computer resources.\n\n::: {#hello .greeting .message style=\"color: red;\"}\n### create 'symlinks' to classdata and my data\n\nLinux `ln` command allows you to create a symbolic link (also symlink or soft link) to a file or directory (called the \"target\") by specifying a path thereto. The format is `ln -s [target location] [shortcut]`. I recommend you create the following symlinks at your root position.\n\n```{bash}\nln -s /mnt/clusters/sponsa/data/classdata classdata\n\nln -s /mnt/clusters/sponsa/data/${USER} mydata\n\nmkdir /mnt/scratch/${USER}\n\nln -s /mnt/scratch/${USER} scratch\n```\n:::\n\nYou should now see two sym links at you root `classdata` and `mydata` that will allow you to address these locations using:\n\n```         \n~/classdata/\n~/mydata/\n```\n\n## Explore your HPC resources\n\n### Your disc quota\n\n::: {.greeting .message style=\"color: red;\"}\nReview what 'storage' resources are available to you.\n\n```         \nquota -us [username]\n```\n:::\n\nThis should display the following information:\n\nDisk quotas for user smbpk (uid 31961):\n\n| Filesystem                           | space | quota | limit | grac | files | quota | limit | grace |\n|--------|--------|--------|--------|--------|--------|--------|--------|--------|\n| /dev/mapper/cl-root                  | 32K   | 5120M | 7168M |      | 13    | 0     | 0     |       |\n| 192.168.2.41:/mnt/data/clusters/anax | 4K    | 1978G | 2078G |      | 6     | 0     | 0     |       |\n\n::: {.greeting .message style=\"color: red;\"}\nCheck your personal disc usage in mydata (du is the disc utility -h = human readable, -s = summarise )\n\n```         \ndu -sh ~/mydata/\n```\n:::\n\n### HPC resources\n\nThe head node on gomphus is a 16 cpu / 32 Gb RAM server.....but it provides access to a series of servers.\n\n::: {.greeting .message style=\"color: red;\"}\nNode Availability\n\nThe head node has a specific script that displays the resources available to you. Run the command:\n\n```         \ngomphus.node_availability.sh\n```\n\nThis should display the following information:\n\n```         \nKey ('CPUS' column):\n  A = # cores Allocated\n  I = # cores Idle\n  O = # cores not 'Idle' or 'Allocated'\n  T = Total # of cores\n```\n\n| NODELIST | NODES | PARTITION | STATE | CPUS | S:C:T  | MEMORY | TMP_DISK | WEIGHT | AVAIL_FE | CPUS(A/I/O/T) | REASON |\n|------|------|------|------|------|------|------|------|------|------|------|------|\n| gomphus2 | 1     | defq\\*    | idle  | 64   | 1:64:1 | 128000  | 0        | 1      | (null)   | 0/64/0/64     | none   |\n| gomphus3 | 1     | defq\\*    | idle  | 64   | 1:64:1 | 440000  | 0        | 1      | (null)   | 0/64/0/64     | none   |\n| gomphus1 | 1     | defq\\*    | idle  | 64   | 1:32:1 | 128000  | 0        | 1      | (null)   | 0/64/0/64     | none   |\n\n:::\n\n# Job Schedulers and Slurm\n\n## The Slurm Job Scheduler\n\nThe slurm job scheduler is software that controls and monitors access to high-performance computing hardware. It allocates resources (cpus/cores/RAM) on a per-job basis.\n\n## Slurm Partitions (Queues)\n\nA number of slurm partitions (queues) may exist on any slurm cluster, and each queue will suit certain types of jobs. Each of the separate queues will handle jobs slightly differently, or will have varying resources available to it. Below is a list of queues available on our HPC systems, and the typical types of jobs they accommodate.\n\n**Gomphus Queues**\n\n| partition(queue) name | default? | description                         |     |\n|-----------------------|----------|-------------------------------------|-----|\n| defq                  | âœ”        | batch jobs, low mem/cpu requirement |     |\n\n## Submitting Jobs (The Slurm Job-Script)\n\nThe typical method to start a job on a slurm cluster is to first create a job-script, then submit that job-script to the slurm queue using the sbatch command. The job-script is laid out in a certain way (examples below), which will first request resources on the compute nodes, and then define the individual steps of your job. Below is an example job script for gomphus slurm using the partition defq. We'll name the job-script `submit.sh`:\n\n```{bash}\n#!/bin/bash\n#SBATCH --partition=defq       # the requested queue\n#SBATCH --nodes=1              # number of nodes to use\n#SBATCH --tasks-per-node=1     #\n#SBATCH --cpus-per-task=1      #   \n#SBATCH --mem-per-cpu=1000     # in megabytes, unless unit explicitly stated\n#SBATCH --error=%J.err         # redirect stderr to this file\n#SBATCH --output=%J.out        # redirect stdout to this file\n##SBATCH --mail-user=[insert email address]@Cardiff.ac.uk  # email address used for event notification\n##SBATCH --mail-type=end                                   # email on job end\n##SBATCH --mail-type=fail                                  # email on job failure\n\necho \"Some Usable Environment Variables:\"\necho \"=================================\"\necho \"hostname=$(hostname)\"\necho \\$SLURM_JOB_ID=${SLURM_JOB_ID}\necho \\$SLURM_NTASKS=${SLURM_NTASKS}\necho \\$SLURM_NTASKS_PER_NODE=${SLURM_NTASKS_PER_NODE}\necho \\$SLURM_CPUS_PER_TASK=${SLURM_CPUS_PER_TASK}\necho \\$SLURM_JOB_CPUS_PER_NODE=${SLURM_JOB_CPUS_PER_NODE}\necho \\$SLURM_MEM_PER_CPU=${SLURM_MEM_PER_CPU}\n\n# Write jobscript to output file (good for reproducibility)\ncat $0\n```\n\nThe job can be submitted from the head node of the slurm cluster using the command:\n\n```         \nsbatch submit.sh\n```\n\nThis particular job does nothing interesting except print out some useful job-specific slurm environment variables, which you may utilise in your job-scripts.\n\nThis job-script is actually just a simple bash script, and in bash the \\# character will comment out the remaining text on that line, and will not be parsed by the bash interpreter. In a slurm job-script however, the lines starting with #SBATCH is parsed by slurm before the script is handed over to the bash interpreter. The #SBATCH lines will inform the slurm scheduler of the amount of resources requested for the job.\n\nIf you would like to comment out certain slurm commands in your job-script, simply add an extra \\# at the beginning of the #SBATCH lines (as we have done in the above example for all email-related commands).\n\nSome further useful (but not exhaustive) SBATCH options are detailed:\n\n| SBATCH option     | Description                                                                                                                                                     |\n|--------------------|----------------------------------------------------|\n| --ntasks-per-node | allocate n tasks per allocated node.                                                                                                                            |\n| --nodes           | set the number of nodes that the job will require. Each node will have --ntasks-per-node processes started                                                      |\n| --ntasks          | spawn n tasks (default=1). This determines how many processes will be spawned (for MPI jobs).                                                                   |\n| --cpus-per-task   | allocate n CPUs per task. This option is needed for multi-threaded jobs. Typically n should be equal to the number of threads your program spawns.              |\n| --partition       | select the partition (queue) where you want to execute your job. Depending on the HPC system you are using, there may, or may not, be much choice.              |\n| --mem-per-cpu     | specify the the memory needed per allocated CPU in MB.                                                                                                          |\n| --job-name        | name your job. This name will be shown in the queue status and email alerts. It is also important for job chaining.                                             |\n| --output          | specify a filename that will be used to store the stdout of your job. The slurm variable %J is useful here which slurm will interpret as the job_id of the job. |\n| --error           | similar to the --output option, but redirect your job's stderr.                                                                                                 |\n\n### Resource Limitations\n\nOn the a slurm cluster, the slurm scheduler keeps track of both requested CPUs, and memory. If your job exceeds the currently available resources then your job will be queued until sufficient resources are available. If your job exceeds the total amount of resources available on the compute nodes then your job submission will fail and will not be queued, in which case an error will be returned.\n\n::: {.greeting .message style=\"color: red;\"}\n## My first slurm Job - Excersise\n\nTo submit an appropriately configured job-script to the slurm queue, use the command:\n\n```{bash}\nsbatch submit.sh\n```\n\nUse `cat` or `less` to rReview the content of the `.out` and `.err` files - note the `.out` file should contain a summary of the varibles used by the script and the program you ran.\n\nThe gomphus cluster has a number of example job-scripts (located under `~/classdata/REFS/slurm` on the gompus.bios.cf.ac.uk server). You may submit these jobs with the following commands on the gomphus cluster:\n\n```{bash}\n# first cd to your allocated ~/mydata/ folder.\nmkdir -p test_jobs && cd test_jobs\ncp ~/classdata/REFS/slurm/slurm_examples/example1/* .\nsbatch example1.sh\n```\n\nWhat is the function of this example script ??\n:::\n\n## Loading programs in slurm scripts\n\nReview what programs are available too you using\n\n```{bash}\nmodule avail\n```\n\nPrograms should be loaded using 'module load' after the slurm parameters have been defined and before you define variable or provide commands for you program.\n\nmodule list for gomphus (2022)\n\n```{bash}\n------------------------------------------------------- /mnt/clusters/sponsa/software/nospack/modulefiles --------------------------------------------------------\napptainer/1.3.3       checkm2/1.0.1-conda  fmlrc/v1.0.0  java/17.0.1          metabat2/2.17-conda  reportseff/v2.7.6  snippy/v4.6.0\nartemis/18.2.0-conda  coverm/0.7.0-conda   go/1.22.4     MAGScoT/1.0.0-conda  mitos/2.0.4-conda    rnammer/1.2        snp-sites/2.5.1\nbioconvert/1.1.1      fastqc/v0.12.1       java/11.0.2   maxbin2/2.2.7-conda  qiime2/2024.5-conda  snakemake/8.20.6   star/2.7.11b-conda\n\n-------------------------------------------- /mnt/clusters/sponsa/software/spack/share/spack/modules/linux-rocky8-zen --------------------------------------------\nabricate/1.0.0-hyc7x7h     caliper/2.11.0-ebmrucn        gatk/4.5.0.0-ah5vlbz          picard/3.1.1-6z7e4l7        python/3.11.7-vwaruyl     vt/0.5772-hm4aagu\nabyss/2.3.5-n7ic7f5        cdhit/4.8.1-kljs53a           grace/5.1.25-6ff2ofq          pilon/1.22-4m44rwk          qualimap/2.2.1-5n2xovw    wtdbg2/2.3-zh2scui\nalan/2.1.1-m3s7v46         dos2unix/7.4.4-lbswpzc        gromacs/2022.6-55ulebd        prokka/1.14.6-mframqo       r/4.4.1-tbzwogp\nbarrnap/0.9-ypa5cto        dyninst/13.0.0-7ddr5br        igv/2.16.2-izjk4b4            py-macs3/3.0.0b3-hzy2kys    raxml-ng/1.1.0-af5tz6w\nbcftools/1.19-ugoqbig      emboss/6.6.0-dyziyqa          kraken2/2.1.2-dj6czbo         py-multiqc/1.15-hcx2o2j     seqtk/1.4-emavr63\nbedtools2/2.31.1-z2zkxtk   fastp/0.23.4-rsrnyej          mafft/7.505-zhsnti2           py-panaroo/1.2.10-ngp4lzx   spades/3.15.5-yabtygn\nblast-plus/2.14.1-qxsspbk  fasttree/2.1.11-ca5e4pn       mcl/14-137-seoyf2k            py-quast/5.2.0-az54c2i      subread/2.0.6-hbzwdut\nbowtie/1.3.1-hcmaf4e       fastx-toolkit/0.0.14-td2y4ek  minimap2/2.28-mpg3455         py-unicycler/0.5.0-b3qlto7  tmux/3.4-goii5an\nbowtie2/2.5.2-xec7g7r      figtree/1.4.4-lbef6u3         perl-xml-simple/2.25-3txxqfi  python/3.7.4-j2ydjpr        trimmomatic/0.39-gkur3wo\nbusco/5.4.3-y2iac7v        freebayes/1.3.6-fwyhw7e       perl/5.34.0-3gr3ksd           python/3.10.5-g77cmwy       velvet/1.2.10-z6f62cw\n\n------------------------------------------------------- /mnt/clusters/gomphus/software/nospack/modulefiles -------------------------------------------------------\napptainer/1.3.3       charliecloud/0.38    fmlrc/v1.0.0  MAGScoT/1.0.0-conda  nextflow/23.10.0     rnammer/1.2       star/2.7.11b-conda\napptainer/1.3.4       checkm2/1.0.1-conda  go/1.22.4     maxbin2/2.2.7-conda  nextflow/24.04.4     snakemake/8.20.6\nartemis/18.2.0-conda  coverm/0.7.0-conda   java/11.0.2   metabat2/2.17-conda  qiime2/2024.5-conda  snippy/v4.6.0\nbioconvert/1.1.1      fastqc/v0.12.1       java/17.0.1   mitos/2.0.4-conda    reportseff/v2.7.6    snp-sites/2.5.1\n\n------------------------------------------- /mnt/clusters/gomphus/software/spack/share/spack/modules/linux-rocky8-zen --------------------------------------------\nabricate/1.0.0-arbowjh     caliper/2.11.0-ebmrucn        gatk/4.5.0.0-ah5vlbz          picard/3.1.1-6z7e4l7        python/3.11.7-vwaruyl     vt/0.5772-hm4aagu\nabyss/2.3.5-n7ic7f5        cdhit/4.8.1-kljs53a           grace/5.1.25-4rbzfg5          pilon/1.22-4m44rwk          qualimap/2.2.1-5n2xovw    wtdbg2/2.3-zh2scui\nalan/2.1.1-m3s7v46         dos2unix/7.4.4-lbswpzc        gromacs/2022.6-55ulebd        prokka/1.14.6-thd4tzv       r/4.4.1-p34wi5a\nbarrnap/0.9-ypa5cto        dyninst/13.0.0-7ddr5br        igv/2.16.2-izjk4b4            py-macs3/3.0.0b3-hzy2kys    raxml-ng/1.1.0-af5tz6w\nbcftools/1.19-kxefepm      emboss/6.6.0-jyqjajy          kraken2/2.1.2-dj6czbo         py-multiqc/1.15-rrs5gki     seqtk/1.4-emavr63\nbedtools2/2.31.1-z2zkxtk   fastp/0.23.4-rsrnyej          mafft/7.505-zhsnti2           py-panaroo/1.2.10-aio7ggr   spades/3.15.5-yabtygn\nblast-plus/2.14.1-ad3m247  fasttree/2.1.11-ca5e4pn       mcl/14-137-seoyf2k            py-quast/5.2.0-ahwdgc2      subread/2.0.6-hbzwdut\nbowtie/1.3.1-hcmaf4e       fastx-toolkit/0.0.14-td2y4ek  minimap2/2.28-mpg3455         py-unicycler/0.5.0-gayhlsi  tmux/3.4-goii5an\nbowtie2/2.5.2-xec7g7r      figtree/1.4.4-lbef6u3         perl-xml-simple/2.25-3txxqfi  python/3.7.4-j2ydjpr        trimmomatic/0.39-gkur3wo\nbusco/5.4.3-lhb6rj4        freebayes/1.3.6-fwyhw7e       perl/5.34.0-3gr3ksd           python/3.10.5-g77cmwy       velvet/1.2.10-z6f62cw\n\n```\n\n## Viewing Information About a Job\n\n### Information on Running Jobs\n\nIf your job-script used the srun command to kick off a (parallel) process, then slurm will be able to provide live information about your running job. All information about your running job can be listed with the sstat command:\n\n```{bash}\nsstat -l -j [jobid]\n```\n\nIn particular it may be useful to compare the fields MaxRSS and ReqMem. These fields report the actual max memory of a single task, and the requested memory of a single task, respectively. You may then tune any future job-scripts to more accurately represent your jobs, which will lead to better queue efficiency - meaning your job will likely start sooner.\n\nIf any application call within your job-script did not use the srun command, then no live information will be available. Instead, wait for your job to finish and use the sacct command, as described below.\n\n### Information on Completed Jobs\n\nSimilar to the `sstat` command used for running jobs, the sacct command will provide equivalent information about completed jobs.\n\n## Useful Slurm-Related Commands\n\nThe sinfo command can supply a lot of useful information about the nodes and available resources. A useful set of parameters of which to call sinfo with is the following:\n\n```{bash}\nsinfo -o \"%24N %.5D %9P %11T %.4c %.8z %.8m %.8d %.6w %8f %15C %20E\"\nNODELIST                 NODES PARTITION STATE       CPUS    S:C:T   MEMORY TMP_DISK WEIGHT AVAIL_FE CPUS(A/I/O/T)   REASON              \ngomphus[1-4]                 4 defq*     idle          32   1:32:1    62250        0      1 (null)   0/128/0/128     none \n```\n\nHere, we see a list of nodes on the gomphus cluster (grouped by partition, and by state), and information about the nodes. In this particular instance we see that gomphus has 4 nodes \\[1-4\\] each with 32 CPUS. The CPUS(A/I/O/T) column shows that the defq partition has a total of 0 CPUs Allocated, 128 CPUs Idle, 0 in state Other, making a Total of 128 (all 4 nodes combined).\n\nThe above command is a bit of a handful. You have already used the wrapper script created for you `gomphus.job_history.sh`\n\n### other useful commands\n\nTo cancel a running job:\n\n```{bash}\n$ scancel [jobid]\n```\n\ninformation about the compute nodes:\n\n```{bash}\n$ sinfo -lNe\n```\n\nList the current status of the slurm queue:\n\n```{bash}\n$ squeue\n```\n\nFind information on previously completed jobs:\n\n```{bash}\n$ sacct\n```\n\nList information on running jobs:\n\n```{bash}\n$ sstat\n```\n\n::: {.greeting .message style=\"color: red;\"}\n## Constructing a slurm Job - good practice\n\nAdapt RNAseq processing script 1-QC.sh (see session Session5 -RNAseq-Processing) to run under slurm (do not run script 2 -- building genome) \\*\\* if you find this easy try adapting script 3,4 and 5.\n\nYou may want to discuss the resources required for the job.\n\nHints:\n\ndefine directories using full path derived with `PWD -P`\n\n```{bash}\n~/mydata/ = /mnt/clusters/sponsa/data/$USER/\n```\n\nWhen creating composite variables use enclose them in quotation marks to ensure they expand.\n\n```{bash}\n\"${indir}/fastq/${i}_1.fastq\"\n```\n:::\n\n## Interactive Jobs\n\nEnter an interactive job and use this to review the files created by the RNAseq processing scripts.\n\n```{bash}\n##Use any available node\nsrun -c 4 --mem=8G -p defq --pty bash\n\n##use a specific node - in this example called gomphus3\n\nsrun -c 4 --mem=8G -p defq --nodelist=gomphus3 --pty bash\n```\n\nRemember to exit the interactive job when you are finished by typing `exit`\n\n***Advanced:*** Some HPC architectures will allow you to directly write to the 'local' harddrive `/tmp` For jobs with lots of I/O and where the nodes are using new M2 SSD drives this can accelerate certain types of jobs.\n\n# Using HPC resources effectively\n\n::: {.greeting .message style=\"color: red;\"}\ngomphus.job_history.sh\n\n| User  | JobID | State     | Start              | End                 | AllocCPUS | TotalCPU  | CPUEf | ReqMem | axRSS    | MemEf | AveDiskRead | AveDiskWrite |\n|------|------|------|------|------|------|------|------|------|------|------|------|------|\n| smbpk | 7174  | COMPLETED | 2022-11-07T09:18:2 | 2022-11-07T09:23:13 | 4         | 05:25.029 | 27.9% | 32000M | 1776696K | 5.4%  | 20940.17M   | 6974.14M     |\n\n:::\n\n## blast as an example\n\nWe take a closer look at running jobs on our cluster, we should provide examples of benchmarking code in order to find how to best utilise the resources available.\n\nWe start off by benchmarking a simple blast job, initially running over a single core, then parallelizing the job using blast's built-in threading. All jobs are run on a single node, and we test a number of nodes and compare results. For example source code, see the folder `~/classdata/REFS/slurm/slurm_examples/indepth_parallelizing_blastp` on the gomphus server.\n\nRemember to run all commands in your `~/mydata/[directory]`.\n\nFirst we obtain the sample data:\n\n```{bash}\n# this is already downloaded to ~/classdata/REFS/slurm/slurm_examples/indepth_parallelizing_blastp/\ncurl -L -o TAIR10_pep.fasta  https://www.arabidopsis.org/download_files/Proteins/TAIR10_protein_lists/TAIR10_pep_20101214\n\n## we can prepare the data within a interactive job\nsrun -c 4 --mem=8G -p defq --pty bash\n\n## navigate to mydata directory\ncd ~/mydata/\n\n## make a dirctory for blast test\nmkdir -p blast_test && cd blast_test \n\n## copy TAIR file accross from class data to local file system\ncp /mnt/clusters/sponsa/data/classdata/Bioinformatics/REFS/slurm/slurm_examples/indepth_parallelizing_blastp/run2_split-files4/TAIR10_pep.fasta .\n\n## Makeblast db from downloaded file\nmodule load blast/2.12.0\nmakeblastdb -in TAIR10_pep.fasta -parse_seqids -dbtype prot -title \"Small protein database\" -out TAIR10_pep\n\n##copy the query sub-set\ncp /mnt/clusters/sponsa/data/classdata/Bioinformatics/REFS/slurm/slurm_examples/indepth_parallelizing_blastp/TAIR10_pep_4000.fasta .\n\nexit\n```\n\nNow create the job Script - blastp.sh\n\n```{bash}\n#!/bin/bash\n#SBATCH --partition=defq       # the requested queue\n#SBATCH --nodes=1              # number of nodes to use\n#SBATCH --tasks-per-node=1     # \n#SBATCH --cpus-per-task=1      #   \n#SBATCH --mem-per-cpu=92000     # in megabytes, unless unit explicitly stated\n#SBATCH --error=%J.err         # redirect stderr to this file\n#SBATCH --output=%J.out        # redirect stdout to this file\n##SBATCH --mail-user=[insert email address]@Cardiff.ac.uk  # email address used for event notification\n##SBATCH --mail-type=start                                 # email on job start  \n##SBATCH --mail-type=end                                   # email on job end\n##SBATCH --mail-type=fail                                  # email on job failure\n\necho \"Usable Environment Variables:\"\necho \"=============================\"\necho \\$SLURM_JOB_ID=${SLURM_JOB_ID} \necho \\$SLURM_NTASKS=${SLURM_NTASKS}\necho \\$SLURM_NTASKS_PER_NODE=${SLURM_NTASKS_PER_NODE}\necho \\$SLURM_CPUS_PER_TASK=${SLURM_CPUS_PER_TASK}\necho \\$SLURM_JOB_CPUS_PER_NODE=${SLURM_JOB_CPUS_PER_NODE}\necho \\$SLURM_MEM_PER_CPU=${SLURM_MEM_PER_CPU}\ncat $0\n\nmodule load blast/2.12.0\n\nindir=\"/mnt/clusters/sponsa/data/${USER}/blast_test\"\n\ndbdir=\"/mnt/clusters/sponsa/data/${USER}/blast_test\"\n\noutdir=\"/mnt/clusters/sponsa/data/${USER}/blast_test\"\n\ntime blastp -num_threads ${SLURM_CPUS_PER_TASK} \\\n            -query \"${indir}/TAIR10_pep_4000.fasta\" \\\n            -task blastp \\\n            -num_descriptions 16 \\\n            -num_alignments 1 \\\n            -db ${dbdir}/TAIR10_pep \\\n            -out \"${outdir}/blastp_cpu${SLURM_CPUS_PER_TASK}_job${SLURM_JOBID}.txt\"\n```\n\n::: {.greeting .message style=\"color: red;\"}\nRun this blast script a number of times, increasing the --cpus-per-task and decreasing the --mem-per-cpu variables accordingly (ie 2 cpus-per-task & 46000 mem-per-cpu, 3 cpus-per-task & 30600 mem-per-cpu .....16 cpus-per-task & 5750 mem-per-cpu. Review the benchmarks considering the resources needed and the time taken to execute the jobs\n\nWhat are your conclusions\n:::\n\n## Reviewing and optimising job resources\n\n::: {.greeting .message style=\"color: red;\"}\nUse `gomphus.job_history.sh` to review the efficiency of your job\n:::\n\n# Threads, MPI and embarrassingly parallel\n\n## Parallel Jobs\n\nThere are a number of different scenarios in which you may want to parallelize your job:\n\n-   Embarrassingly parallel\n-   MPI - a multi-process application (possibly across multiple compute hosts)\n-   multi-threading - shared memory using OpenMP or perhaps pthreads.\n-   multiple instances of a single application.\n-   ...plus more scenarios but are probably out of scope of this tutorial.\n\n## Embarrassingly parallel\n\nMany processes in genomics do the same task on large arrays of data. One of the simplest way of speeding up the process is to split up the input files and perfrom the same task multiple times at the same time - this is called an \\_**'Embarrassingly parallel'** task.\n\nLets do this for the blast example that we started in the last task. We can investigate whether there are any further methods of improving performance, and attempt to find a improvemet in the initial blast job's solution to reduce the time taken. As it turns out, it is possible in this situation to split the input fasta file into a number of sections, and have an independent job acting on each of those sections. Each independent job could then be parallelized, say over 8 threads, and all jobs can run concurrently.\n\nWe create a job script (mammoth_8thread_split_1of4.sh) that will run blast command on the first file-section only.\n\nWe perform the following sequence of commands, first splitting the input fasta file into 4 parts, then creating the 4 independent job-scripts, and submit the jobs.\n\n```{bash}\n## enter a interactive Job\nsrun -c 4 --mem=8G -p defq --pty bash\ncd ~/mydata/blast_test/\n\n## a new folder\nmkdir split-files4\ncd split-files4/\ncp ~/TAIR10_pep_4000.fasta  .\n#\n## split the fasta file into 4 equal(ish) sections\ncurl -L https://raw.githubusercontent.com/gmarnellos/Trinotate_example_supplement/master/split_fasta.pl | perl /dev/stdin  TAIR10_pep_4000.fasta  TAIR10_pep.vol 1000\n```\n\ncreate script that will spawn blast_jobs (use nano or vi) - spawn_blastp.sh\n\n```{bash}\n!#/bin/bash\n\nfor i in {1..4};do\n\nexport i\n\nsbatch blastp.sh\n\ndone\n```\n\nmake script executable `chmod +x spawn_blastp.sh`\n\nEdit blast job so that each time it is called it uses a different section of the query file\n\n```{bash}\n#!/bin/bash\n#SBATCH --partition=defq       # the requested queue\n#SBATCH --nodes=1              # number of nodes to use\n#SBATCH --tasks-per-node=1     # \n#SBATCH --cpus-per-task=8      #   \n#SBATCH --mem-per-cpu=11500    # in megabytes, unless unit explicitly stated\n#SBATCH --error=%J.err         # redirect stderr to this file\n#SBATCH --output=%J.out        # redirect stdout to this file\n##SBATCH --mail-user=[insert email address]@Cardiff.ac.uk  # email address used for event notification\n##SBATCH --mail-type=start                                 # email on job start  \n##SBATCH --mail-type=end                                   # email on job end\n##SBATCH --mail-type=fail                                  # email on job failure\n\necho \"Usable Environment Variables:\"\necho \"=============================\"\necho \"hostname=$(hostname)\"\necho \\$SLURM_JOB_ID=${SLURM_JOB_ID} \necho \\$SLURM_NTASKS=${SLURM_NTASKS}\necho \\$SLURM_NTASKS_PER_NODE=${SLURM_NTASKS_PER_NODE}\necho \\$SLURM_CPUS_PER_TASK=${SLURM_CPUS_PER_TASK}\necho \\$SLURM_JOB_CPUS_PER_NODE=${SLURM_JOB_CPUS_PER_NODE}\necho \\$SLURM_MEM_PER_CPU=${SLURM_MEM_PER_CPU}\n\ncat $0\n\nmodule load blast/2.12.0\n\nindir=\"/mnt/clusters/sponsa/data/${USER}/blast_test/split-files4\"\n\ndbdir=\"/mnt/clusters/sponsa/data/${USER}/blast_test\"\n\noutdir=\"/mnt/clusters/sponsa/data/${USER}/blast_test/split-files4\"\n\ntime blastp -num_threads ${SLURM_CPUS_PER_TASK} \\\n            -query \"${indir}/TAIR10_pep.vol.${i}.fasta\" \\\n            -task blastp \\\n            -num_descriptions 16 \\\n            -num_alignments 1 \\\n            -db ${dbdir}/TAIR10_pep \\\n            -out \"${outdir}/blastp_vol${i}_cpu${SLURM_CPUS_PER_TASK}_job${SLURM_JOBID}.txt\"\n```\n\nPerform file-splitting procedure for both a 2-split and a 4-split of the original fasta file. The 'time-to-solution' results are added to the original benchmark chart. We assume that all jobs run concurrently, and we take the wall-time for the longest job\n\n## MPI Jobs\n\nOur example MPI job is based on a quantum espresso calculation. This script utilises the srun command, which is part of the slurm family of tools to run a parallel job on a cluster\n\n```{bash}\n#!/bin/bash\n#SBATCH --partition=mammoth    # the requested queue\n#SBATCH --job-name=qe_mpi      # name the job           \n#SBATCH --nodes=1              # number of nodes to use\n#SBATCH --ntasks=32            # total number of tasks (processes)\n#SBATCH --mem-per-cpu=100      # in megabytes, unless unit explicitly stated\n#SBATCH --error=%J.err         # redirect stderr to this file\n#SBATCH --output=%J.out        # redirect stdout to this file\n##SBATCH --mail-user=[insert email address]@Cardiff.ac.uk  # email address used for event notification\n##SBATCH --mail-type=end                                   # email on job end\n##SBATCH --mail-type=fail                                  # email on job failure\n\nmodule load  qe/6.0\n\necho \"Usable Environment Variables:\"\necho \"=============================\"\necho \"hostname=$(hostname)\"\necho \\$SLURM_JOB_ID=${SLURM_JOB_ID}\necho \\$SLURM_NTASKS=${SLURM_NTASKS}\necho \\$SLURM_NTASKS_PER_NODE=${SLURM_NTASKS_PER_NODE}\necho \\$SLURM_CPUS_PER_TASK=${SLURM_CPUS_PER_TASK}\necho \\$SLURM_JOB_CPUS_PER_NODE=${SLURM_JOB_CPUS_PER_NODE}\necho \\$SLURM_MEM_PER_CPU=${SLURM_MEM_PER_CPU}\necho \"module list:\"\nmodule list 2>&1\n\n# Some of these environment variables are utilised by the qe executable itself\nexport ESPRESSO_DATAPATH=/mnt/clusters/sponsa/data/classdata/Bioinformatics/REFS/slurm/slurm_examples/example2_mpi/\nexport ESPRESSO_PSEUDO=${ESPRESSO_DATAPATH}\nexport ESPRESSO_TMPDIR=${ESPRESSO_DATAPATH}/${SLURM_JOB_ID}\n\n# handy to place this in job output for future reference...\ncat ${ESPRESSO_DATAPATH}/atom.in\n\n# execute the parallel job (we also time it)\ntime srun -n ${SLURM_NTASKS} pw.x < ${ESPRESSO_DATAPATH}/atom.in > atom.job${SLURM_JOB_ID}.out\n```\n\nThe job requests 32 cores to be allocated, and runs the srun command with the argument -n \\${SLURM_NTASKS} which tells srun to spawn the mpi-job with the total number of processes requested. Quantum Espresso utilises the environment variable ESPRESSO_TMPDIR which points to a temporary folder. We design this in our slurm script to point to a subfolder.\n\nAn alternative storage location is the compute node's local storage. This can improve runtime I/O performance. However, local storage on the compute nodes is limited (Gigabytes not Terabytes), and it's availability is a little hidden from the user, so take care not to fill up the disk(!) and remove all files from the compute node's local storage within the job script (your only access to the compute node's /local folder is via the slurm script). An alternative job script which utilises a compute node's /local storage is provided on the gomphus server /mnt/clusters/sponsa/data/classdata/Bioinformatics/REFS/slurm/slurm_examples/example2_mpi/example2_mpi_localstorage.sh.\n\n## Threaded Jobs\n\nA number of popular bioinformatics software are capable of parallelising execution using threads (usually OpenMP or pthreads). This parallelisation method does not normally use distributed memory, so the application will need to be run on a single node. Our threaded example slurm-script is based on BLAST+. The job script is listed:\n\n```{bash}\n#!/bin/bash\n#SBATCH --partition=defq\n#SBATCH --nodes=1\n#SBATCH --tasks-per-node=1\n#SBATCH --cpus-per-task=8\n#SBATCH --mem-per-cpu=2000\n#SBATCH --error=%J.err\n#SBATCH --output=%J.out\n##SBATCH --mail-type=end\n##SBATCH --mail-user=[your.email@address]\n\n\n# Example slurm script\n#  This script is a little wasteful of resources,\n#  but demonstrates a simple pipeline.\n#  \n#  For a more efficient use of resources, please consider\n#  running the pipeline as a series of jobs (chain-jobs).\n\n\necho \"Usable Environment Variables:\"\necho \"=============================\"\necho \"hostname=$(hostname)\"\necho \\$SLURM_JOB_ID=${SLURM_JOB_ID}\necho \\$SLURM_NTASKS=${SLURM_NTASKS}\necho \\$SLURM_NTASKS_PER_NODE=${SLURM_NTASKS_PER_NODE}\necho \\$SLURM_CPUS_PER_TASK=${SLURM_CPUS_PER_TASK}\necho \\$SLURM_JOB_CPUS_PER_NODE=${SLURM_JOB_CPUS_PER_NODE}\necho \\$SLURM_MEM_PER_CPU=${SLURM_MEM_PER_CPU}\necho \"module list:\"\nmodule list 2>&1\n\nDATAFOLDER=/mnt/clusters/sponsa/data/classdata/Bioinformatics/REFS/slurm/slurm_examples/example3_pipeline\n\n\n### The data used in this pipeline has already been downloaded and stored in $DATAFOLDER.\n### Here are the commands used to download the data...\n# cd $DATAFOLDER\n# curl -LO https://data.broadinstitute.org/Trinity/Trinotate_v2.0_RESOURCES/uniprot_sprot.trinotate_v2.0.pep.gz\n# gunzip uniprot_sprot.trinotate_v2.0.pep.gz\n# curl -LO https://data.broadinstitute.org/Trinity/Trinotate_v2.0_RESOURCES/Pfam-A.hmm.gz\n# gunzip Pfam-A.hmm.gz\n# curl -L -o Trinotate.sqlite.gz https://data.broadinstitute.org/Trinity/Trinotate_v2.0_RESOURCES/Trinotate.sprot_uniref90.20150131.boilerplate.sqlite.gz\n# gunzip Trinotate.sqlite.gz\n# curl -LO ftp://ftp.ensembl.org/pub/release-82/fasta/mus_musculus/cdna/Mus_musculus.GRCm38.cdna.all.fa.gz\n# gunzip Mus_musculus.GRCm38.cdna.all.fa.gz\n# curl -LOgz https://github.com/gmarnellos/Trinotate_example_supplement/raw/master/mouse38_cdna.fa.gz\n# gunzip mouse38_cdna.fa.gz\n\n# Now we get on to the pipeline\n\n# make a link to all datafiles\nfor f in ${DATAFOLDER}/* ; do ln -s $f ; done\n\n#Index the SwissProt database for use with blast\n\nmodule load blast\nmakeblastdb -version\nmakeblastdb -in uniprot_sprot.trinotate_v2.0.pep -dbtype prot\nmodule unload blast\n\n# Prepare the Pfam database for use with hmmscan\nmodule load hmmer\nhmmpress -h\nhmmpress Pfam-A.hmm\nmodule load hmmer\n\n# Use Transdecoder to produce the most likely longest-ORF peptide candidates\nmodule load TransDecoder/v3.0.1\nTransDecoder.LongOrfs -t mouse38_cdna.fa\nTransDecoder.Predict -t mouse38_cdna.fa\nmodule unload TransDecoder/v3.0.1\n\nmodule load blast\nblastx -query mouse38_cdna.fa -db uniprot_sprot.trinotate.pep -num_threads ${SLURM_CPUS_PER_TASK} -max_target_seqs 1 -outfmt 6 > blastx.vol.outfmt6\nblastp -query mouse38_cdna.fa.transdecoder.pep -db uniprot_sprot.trinotate_v2.0.pep -num_threads ${SLURM_CPUS_PER_TASK} -max_target_seqs 1 -outfmt 6 > blastp.vol.outfmt6\nmodule unload blast\n\n# Identify protein domains\nmodule load hmmer/3.1b2\nhmmscan --cpu ${SLURM_CPUS_PER_TASK} --domtblout TrinotatePFAM.out Pfam-A.hmm mouse38_cdna.fa.transdecoder.pep > pfam.log\nmodule unload hmmer/3.1b2\n\n# Produce the Gene/Transcript relationship\ngrep \"^>\" Mus_musculus.GRCm38.cdna.all.fa   | perl -p -e 's/^>(\\S+).*\\s+gene:(ENSMUSG\\d+).*$/$2\\t$1/' > gene_transcript_map.txt\n\n# Now populate the sqlite database\nmodule load Trinotate/v3.0.1\nTrinotate Trinotate.sqlite init --gene_trans_map gene_transcript_map.txt --transcript_fasta mouse38_cdna.fa --transdecoder_pep mouse38_cdna.fa.transdecoder.pep\nTrinotate Trinotate.sqlite LOAD_swissprot_blastp blastp.vol.outfmt6\nTrinotate Trinotate.sqlite LOAD_swissprot_blastx blastx.vol.outfmt6\nTrinotate Trinotate.sqlite LOAD_pfam TrinotatePFAM.out\n# Create the annotation report\nTrinotate Trinotate.sqlite report -E 0.00001 > trinotate_annotation_report.xls\nmodule unload Trinotate/v3.0.1\n```\n\nThis is quite a busy job-script (and also inefficient on resources!). It runs through a number of steps, but some of those steps will utilise parallelisation via threading, and use the slurm environment variable SLURM_CPUS_PER_TASK to inform the application(s) of the correct number of threads.\n\nBut why is this job inefficient on resources? This particular job involves a number of steps: some utilising parallelisation, and some not; some memory-hungry, others not. The problem with this is that the job has allocated to it a set amount of resources (compute and memory), which is allocated to it for the lifetime of the job. But only at certain times in this job are the resources requested fully utilised. At all other times this job is running, the resources are allocated, but not used, and therefore making those resources unavailable to other jobs. This has a knock-on effect of increasing queue-times, and leaves expensive resources idle.\n\nA much more efficient way of running the same pipeline is to chain the job - split the pipeline into component parts and submit separate jobs for each of those parts. Each section of the pipeline (having its own job-script) is then free to allocate resources specific to that section of the pipeline. In the slurm world this is called job chaining, and has been exemplified in the next section using the same pipeline.\n\n## Job Chains and Job Dependency\n\nChaining jobs is a method of sequentially running dependent jobs. Our chain-job example is a pipeline of 6 separate job scripts, based on the blast+ pipeline of the previous section. We do not show the full six job-scripts here for brevity, but are available on the gomphus cluster under /mnt/clusters/sponsa/data/classdata/Bioinformatics/REFS/slurm/slurm_examples/example4_chain.\n\nSlurm has an option -d or --dependency that allows to specify that a job is only permitted to start if another job finished successfully.\n\nIn the folder (gomphus cluster) /mnt/clusters/sponsa/data/classdata/Bioinformatics/REFS/slurm/slurm_examples/example4_chain there are 6 separate job-scripts that need to be executed in a certain order. They are numbered in the correct pipeline order:\n\n```{bash}\n[user@gomphus ~]$ tree  /mnt/clusters/sponsa/data/classdata/Bioinformatics/REFS/slurm/slurm_examples/example4_chain\n/mnt/clusters/sponsa/data/classdata/Bioinformatics/REFS/slurm/slurm_examples/example4_chain\nâ”œâ”€â”€ example4_chain-step1.sh\nâ”œâ”€â”€ example4_chain-step2.sh\nâ”œâ”€â”€ example4_chain-step3.sh\nâ”œâ”€â”€ example4_chain-step4.sh\nâ”œâ”€â”€ example4_chain-step5.sh\nâ”œâ”€â”€ example4_chain-step6.sh\nâ”œâ”€â”€ example4_submit_all.sh\nâ”œâ”€â”€ mouse38_cdna.fa\nâ”œâ”€â”€ Mus_musculus.GRCm38.cdna.all.fa\nâ”œâ”€â”€ Pfam-A.hmm\nâ”œâ”€â”€ pipeline1.sh\nâ”œâ”€â”€ Trinotate.sqlite\nâ””â”€â”€ uniprot_sprot.trinotate_v2.0.pep\n\n0 directories, 13 files\n```\n\nEach job is (importantly) commonly named using #SBATCH --job-name within each job-script. Also within this folder is a simple script (example4_submit_all.sh) that will execute the sbatch command on each of the job-scripts in the correct order:\n\n```{bash}\n#!/bin/bash:\n\nfor c in /mnt/clusters/sponsa/data/classdata/Bioinformatics/REFS/slurm/slurm_examples/example4_chain/example4_chain-step?.sh ;\ndo\n sbatch -d singleton $c\ndone\n```\n\nThis sbatch command uses the -d singleton flag to notify slurm of the job-dependencies (all jobs must have the name job name defined by `#SBATCH --job-name [some constant name]`. At which point each submitted job will be forced to depend on successful completion of any previous job submitted by the same user, and with the same job-name. The full pipeline of 6 jobs will now run to completion, with no further user-intervention, making efficient use of the available resources.\n","srcMarkdownNoYaml":"\n\n<body style=\"background-color:gray99;\">\n\n```{r include=FALSE}\nknitr::opts_chunk$set(eval = FALSE)\n```\n\n![](Images/logo.jpg){width=\"10%\"}\n\n# My HPC System\n\nAll HPC are slightly different and it is important to understand the specific system you are using. The current activities cover relate to the IT infrastructure provided to Big Data Masters student at Cardiff University session 2022-23. If you are not part of this class then you will need to request appropriate information about the system you have been given access to.\n\n## House Keeping\n\n### login to the server\n\nHPC system available to big data masters students:\n\nhost\n\n```{bash}\ngomphus.bios.cf.ac.uk\n```\n\nUser name `university username` Password `SSO Password` Port `22`\n\nWe suggest you use (MobaXterm)\\[<https://mobaxterm.mobatek.net/>\\] (PC) and terminal SSH (Mac) to access the server and MobaXtrem and (cyberduck)\\[<https://cyberduck.io/>\\] or (filezilla)\\[<https://filezilla-project.org/>\\] to allow secure file transfer (sftp) between server and local computer resources.\n\n::: {#hello .greeting .message style=\"color: red;\"}\n### create 'symlinks' to classdata and my data\n\nLinux `ln` command allows you to create a symbolic link (also symlink or soft link) to a file or directory (called the \"target\") by specifying a path thereto. The format is `ln -s [target location] [shortcut]`. I recommend you create the following symlinks at your root position.\n\n```{bash}\nln -s /mnt/clusters/sponsa/data/classdata classdata\n\nln -s /mnt/clusters/sponsa/data/${USER} mydata\n\nmkdir /mnt/scratch/${USER}\n\nln -s /mnt/scratch/${USER} scratch\n```\n:::\n\nYou should now see two sym links at you root `classdata` and `mydata` that will allow you to address these locations using:\n\n```         \n~/classdata/\n~/mydata/\n```\n\n## Explore your HPC resources\n\n### Your disc quota\n\n::: {.greeting .message style=\"color: red;\"}\nReview what 'storage' resources are available to you.\n\n```         \nquota -us [username]\n```\n:::\n\nThis should display the following information:\n\nDisk quotas for user smbpk (uid 31961):\n\n| Filesystem                           | space | quota | limit | grac | files | quota | limit | grace |\n|--------|--------|--------|--------|--------|--------|--------|--------|--------|\n| /dev/mapper/cl-root                  | 32K   | 5120M | 7168M |      | 13    | 0     | 0     |       |\n| 192.168.2.41:/mnt/data/clusters/anax | 4K    | 1978G | 2078G |      | 6     | 0     | 0     |       |\n\n::: {.greeting .message style=\"color: red;\"}\nCheck your personal disc usage in mydata (du is the disc utility -h = human readable, -s = summarise )\n\n```         \ndu -sh ~/mydata/\n```\n:::\n\n### HPC resources\n\nThe head node on gomphus is a 16 cpu / 32 Gb RAM server.....but it provides access to a series of servers.\n\n::: {.greeting .message style=\"color: red;\"}\nNode Availability\n\nThe head node has a specific script that displays the resources available to you. Run the command:\n\n```         \ngomphus.node_availability.sh\n```\n\nThis should display the following information:\n\n```         \nKey ('CPUS' column):\n  A = # cores Allocated\n  I = # cores Idle\n  O = # cores not 'Idle' or 'Allocated'\n  T = Total # of cores\n```\n\n| NODELIST | NODES | PARTITION | STATE | CPUS | S:C:T  | MEMORY | TMP_DISK | WEIGHT | AVAIL_FE | CPUS(A/I/O/T) | REASON |\n|------|------|------|------|------|------|------|------|------|------|------|------|\n| gomphus2 | 1     | defq\\*    | idle  | 64   | 1:64:1 | 128000  | 0        | 1      | (null)   | 0/64/0/64     | none   |\n| gomphus3 | 1     | defq\\*    | idle  | 64   | 1:64:1 | 440000  | 0        | 1      | (null)   | 0/64/0/64     | none   |\n| gomphus1 | 1     | defq\\*    | idle  | 64   | 1:32:1 | 128000  | 0        | 1      | (null)   | 0/64/0/64     | none   |\n\n:::\n\n# Job Schedulers and Slurm\n\n## The Slurm Job Scheduler\n\nThe slurm job scheduler is software that controls and monitors access to high-performance computing hardware. It allocates resources (cpus/cores/RAM) on a per-job basis.\n\n## Slurm Partitions (Queues)\n\nA number of slurm partitions (queues) may exist on any slurm cluster, and each queue will suit certain types of jobs. Each of the separate queues will handle jobs slightly differently, or will have varying resources available to it. Below is a list of queues available on our HPC systems, and the typical types of jobs they accommodate.\n\n**Gomphus Queues**\n\n| partition(queue) name | default? | description                         |     |\n|-----------------------|----------|-------------------------------------|-----|\n| defq                  | âœ”        | batch jobs, low mem/cpu requirement |     |\n\n## Submitting Jobs (The Slurm Job-Script)\n\nThe typical method to start a job on a slurm cluster is to first create a job-script, then submit that job-script to the slurm queue using the sbatch command. The job-script is laid out in a certain way (examples below), which will first request resources on the compute nodes, and then define the individual steps of your job. Below is an example job script for gomphus slurm using the partition defq. We'll name the job-script `submit.sh`:\n\n```{bash}\n#!/bin/bash\n#SBATCH --partition=defq       # the requested queue\n#SBATCH --nodes=1              # number of nodes to use\n#SBATCH --tasks-per-node=1     #\n#SBATCH --cpus-per-task=1      #   \n#SBATCH --mem-per-cpu=1000     # in megabytes, unless unit explicitly stated\n#SBATCH --error=%J.err         # redirect stderr to this file\n#SBATCH --output=%J.out        # redirect stdout to this file\n##SBATCH --mail-user=[insert email address]@Cardiff.ac.uk  # email address used for event notification\n##SBATCH --mail-type=end                                   # email on job end\n##SBATCH --mail-type=fail                                  # email on job failure\n\necho \"Some Usable Environment Variables:\"\necho \"=================================\"\necho \"hostname=$(hostname)\"\necho \\$SLURM_JOB_ID=${SLURM_JOB_ID}\necho \\$SLURM_NTASKS=${SLURM_NTASKS}\necho \\$SLURM_NTASKS_PER_NODE=${SLURM_NTASKS_PER_NODE}\necho \\$SLURM_CPUS_PER_TASK=${SLURM_CPUS_PER_TASK}\necho \\$SLURM_JOB_CPUS_PER_NODE=${SLURM_JOB_CPUS_PER_NODE}\necho \\$SLURM_MEM_PER_CPU=${SLURM_MEM_PER_CPU}\n\n# Write jobscript to output file (good for reproducibility)\ncat $0\n```\n\nThe job can be submitted from the head node of the slurm cluster using the command:\n\n```         \nsbatch submit.sh\n```\n\nThis particular job does nothing interesting except print out some useful job-specific slurm environment variables, which you may utilise in your job-scripts.\n\nThis job-script is actually just a simple bash script, and in bash the \\# character will comment out the remaining text on that line, and will not be parsed by the bash interpreter. In a slurm job-script however, the lines starting with #SBATCH is parsed by slurm before the script is handed over to the bash interpreter. The #SBATCH lines will inform the slurm scheduler of the amount of resources requested for the job.\n\nIf you would like to comment out certain slurm commands in your job-script, simply add an extra \\# at the beginning of the #SBATCH lines (as we have done in the above example for all email-related commands).\n\nSome further useful (but not exhaustive) SBATCH options are detailed:\n\n| SBATCH option     | Description                                                                                                                                                     |\n|--------------------|----------------------------------------------------|\n| --ntasks-per-node | allocate n tasks per allocated node.                                                                                                                            |\n| --nodes           | set the number of nodes that the job will require. Each node will have --ntasks-per-node processes started                                                      |\n| --ntasks          | spawn n tasks (default=1). This determines how many processes will be spawned (for MPI jobs).                                                                   |\n| --cpus-per-task   | allocate n CPUs per task. This option is needed for multi-threaded jobs. Typically n should be equal to the number of threads your program spawns.              |\n| --partition       | select the partition (queue) where you want to execute your job. Depending on the HPC system you are using, there may, or may not, be much choice.              |\n| --mem-per-cpu     | specify the the memory needed per allocated CPU in MB.                                                                                                          |\n| --job-name        | name your job. This name will be shown in the queue status and email alerts. It is also important for job chaining.                                             |\n| --output          | specify a filename that will be used to store the stdout of your job. The slurm variable %J is useful here which slurm will interpret as the job_id of the job. |\n| --error           | similar to the --output option, but redirect your job's stderr.                                                                                                 |\n\n### Resource Limitations\n\nOn the a slurm cluster, the slurm scheduler keeps track of both requested CPUs, and memory. If your job exceeds the currently available resources then your job will be queued until sufficient resources are available. If your job exceeds the total amount of resources available on the compute nodes then your job submission will fail and will not be queued, in which case an error will be returned.\n\n::: {.greeting .message style=\"color: red;\"}\n## My first slurm Job - Excersise\n\nTo submit an appropriately configured job-script to the slurm queue, use the command:\n\n```{bash}\nsbatch submit.sh\n```\n\nUse `cat` or `less` to rReview the content of the `.out` and `.err` files - note the `.out` file should contain a summary of the varibles used by the script and the program you ran.\n\nThe gomphus cluster has a number of example job-scripts (located under `~/classdata/REFS/slurm` on the gompus.bios.cf.ac.uk server). You may submit these jobs with the following commands on the gomphus cluster:\n\n```{bash}\n# first cd to your allocated ~/mydata/ folder.\nmkdir -p test_jobs && cd test_jobs\ncp ~/classdata/REFS/slurm/slurm_examples/example1/* .\nsbatch example1.sh\n```\n\nWhat is the function of this example script ??\n:::\n\n## Loading programs in slurm scripts\n\nReview what programs are available too you using\n\n```{bash}\nmodule avail\n```\n\nPrograms should be loaded using 'module load' after the slurm parameters have been defined and before you define variable or provide commands for you program.\n\nmodule list for gomphus (2022)\n\n```{bash}\n------------------------------------------------------- /mnt/clusters/sponsa/software/nospack/modulefiles --------------------------------------------------------\napptainer/1.3.3       checkm2/1.0.1-conda  fmlrc/v1.0.0  java/17.0.1          metabat2/2.17-conda  reportseff/v2.7.6  snippy/v4.6.0\nartemis/18.2.0-conda  coverm/0.7.0-conda   go/1.22.4     MAGScoT/1.0.0-conda  mitos/2.0.4-conda    rnammer/1.2        snp-sites/2.5.1\nbioconvert/1.1.1      fastqc/v0.12.1       java/11.0.2   maxbin2/2.2.7-conda  qiime2/2024.5-conda  snakemake/8.20.6   star/2.7.11b-conda\n\n-------------------------------------------- /mnt/clusters/sponsa/software/spack/share/spack/modules/linux-rocky8-zen --------------------------------------------\nabricate/1.0.0-hyc7x7h     caliper/2.11.0-ebmrucn        gatk/4.5.0.0-ah5vlbz          picard/3.1.1-6z7e4l7        python/3.11.7-vwaruyl     vt/0.5772-hm4aagu\nabyss/2.3.5-n7ic7f5        cdhit/4.8.1-kljs53a           grace/5.1.25-6ff2ofq          pilon/1.22-4m44rwk          qualimap/2.2.1-5n2xovw    wtdbg2/2.3-zh2scui\nalan/2.1.1-m3s7v46         dos2unix/7.4.4-lbswpzc        gromacs/2022.6-55ulebd        prokka/1.14.6-mframqo       r/4.4.1-tbzwogp\nbarrnap/0.9-ypa5cto        dyninst/13.0.0-7ddr5br        igv/2.16.2-izjk4b4            py-macs3/3.0.0b3-hzy2kys    raxml-ng/1.1.0-af5tz6w\nbcftools/1.19-ugoqbig      emboss/6.6.0-dyziyqa          kraken2/2.1.2-dj6czbo         py-multiqc/1.15-hcx2o2j     seqtk/1.4-emavr63\nbedtools2/2.31.1-z2zkxtk   fastp/0.23.4-rsrnyej          mafft/7.505-zhsnti2           py-panaroo/1.2.10-ngp4lzx   spades/3.15.5-yabtygn\nblast-plus/2.14.1-qxsspbk  fasttree/2.1.11-ca5e4pn       mcl/14-137-seoyf2k            py-quast/5.2.0-az54c2i      subread/2.0.6-hbzwdut\nbowtie/1.3.1-hcmaf4e       fastx-toolkit/0.0.14-td2y4ek  minimap2/2.28-mpg3455         py-unicycler/0.5.0-b3qlto7  tmux/3.4-goii5an\nbowtie2/2.5.2-xec7g7r      figtree/1.4.4-lbef6u3         perl-xml-simple/2.25-3txxqfi  python/3.7.4-j2ydjpr        trimmomatic/0.39-gkur3wo\nbusco/5.4.3-y2iac7v        freebayes/1.3.6-fwyhw7e       perl/5.34.0-3gr3ksd           python/3.10.5-g77cmwy       velvet/1.2.10-z6f62cw\n\n------------------------------------------------------- /mnt/clusters/gomphus/software/nospack/modulefiles -------------------------------------------------------\napptainer/1.3.3       charliecloud/0.38    fmlrc/v1.0.0  MAGScoT/1.0.0-conda  nextflow/23.10.0     rnammer/1.2       star/2.7.11b-conda\napptainer/1.3.4       checkm2/1.0.1-conda  go/1.22.4     maxbin2/2.2.7-conda  nextflow/24.04.4     snakemake/8.20.6\nartemis/18.2.0-conda  coverm/0.7.0-conda   java/11.0.2   metabat2/2.17-conda  qiime2/2024.5-conda  snippy/v4.6.0\nbioconvert/1.1.1      fastqc/v0.12.1       java/17.0.1   mitos/2.0.4-conda    reportseff/v2.7.6    snp-sites/2.5.1\n\n------------------------------------------- /mnt/clusters/gomphus/software/spack/share/spack/modules/linux-rocky8-zen --------------------------------------------\nabricate/1.0.0-arbowjh     caliper/2.11.0-ebmrucn        gatk/4.5.0.0-ah5vlbz          picard/3.1.1-6z7e4l7        python/3.11.7-vwaruyl     vt/0.5772-hm4aagu\nabyss/2.3.5-n7ic7f5        cdhit/4.8.1-kljs53a           grace/5.1.25-4rbzfg5          pilon/1.22-4m44rwk          qualimap/2.2.1-5n2xovw    wtdbg2/2.3-zh2scui\nalan/2.1.1-m3s7v46         dos2unix/7.4.4-lbswpzc        gromacs/2022.6-55ulebd        prokka/1.14.6-thd4tzv       r/4.4.1-p34wi5a\nbarrnap/0.9-ypa5cto        dyninst/13.0.0-7ddr5br        igv/2.16.2-izjk4b4            py-macs3/3.0.0b3-hzy2kys    raxml-ng/1.1.0-af5tz6w\nbcftools/1.19-kxefepm      emboss/6.6.0-jyqjajy          kraken2/2.1.2-dj6czbo         py-multiqc/1.15-rrs5gki     seqtk/1.4-emavr63\nbedtools2/2.31.1-z2zkxtk   fastp/0.23.4-rsrnyej          mafft/7.505-zhsnti2           py-panaroo/1.2.10-aio7ggr   spades/3.15.5-yabtygn\nblast-plus/2.14.1-ad3m247  fasttree/2.1.11-ca5e4pn       mcl/14-137-seoyf2k            py-quast/5.2.0-ahwdgc2      subread/2.0.6-hbzwdut\nbowtie/1.3.1-hcmaf4e       fastx-toolkit/0.0.14-td2y4ek  minimap2/2.28-mpg3455         py-unicycler/0.5.0-gayhlsi  tmux/3.4-goii5an\nbowtie2/2.5.2-xec7g7r      figtree/1.4.4-lbef6u3         perl-xml-simple/2.25-3txxqfi  python/3.7.4-j2ydjpr        trimmomatic/0.39-gkur3wo\nbusco/5.4.3-lhb6rj4        freebayes/1.3.6-fwyhw7e       perl/5.34.0-3gr3ksd           python/3.10.5-g77cmwy       velvet/1.2.10-z6f62cw\n\n```\n\n## Viewing Information About a Job\n\n### Information on Running Jobs\n\nIf your job-script used the srun command to kick off a (parallel) process, then slurm will be able to provide live information about your running job. All information about your running job can be listed with the sstat command:\n\n```{bash}\nsstat -l -j [jobid]\n```\n\nIn particular it may be useful to compare the fields MaxRSS and ReqMem. These fields report the actual max memory of a single task, and the requested memory of a single task, respectively. You may then tune any future job-scripts to more accurately represent your jobs, which will lead to better queue efficiency - meaning your job will likely start sooner.\n\nIf any application call within your job-script did not use the srun command, then no live information will be available. Instead, wait for your job to finish and use the sacct command, as described below.\n\n### Information on Completed Jobs\n\nSimilar to the `sstat` command used for running jobs, the sacct command will provide equivalent information about completed jobs.\n\n## Useful Slurm-Related Commands\n\nThe sinfo command can supply a lot of useful information about the nodes and available resources. A useful set of parameters of which to call sinfo with is the following:\n\n```{bash}\nsinfo -o \"%24N %.5D %9P %11T %.4c %.8z %.8m %.8d %.6w %8f %15C %20E\"\nNODELIST                 NODES PARTITION STATE       CPUS    S:C:T   MEMORY TMP_DISK WEIGHT AVAIL_FE CPUS(A/I/O/T)   REASON              \ngomphus[1-4]                 4 defq*     idle          32   1:32:1    62250        0      1 (null)   0/128/0/128     none \n```\n\nHere, we see a list of nodes on the gomphus cluster (grouped by partition, and by state), and information about the nodes. In this particular instance we see that gomphus has 4 nodes \\[1-4\\] each with 32 CPUS. The CPUS(A/I/O/T) column shows that the defq partition has a total of 0 CPUs Allocated, 128 CPUs Idle, 0 in state Other, making a Total of 128 (all 4 nodes combined).\n\nThe above command is a bit of a handful. You have already used the wrapper script created for you `gomphus.job_history.sh`\n\n### other useful commands\n\nTo cancel a running job:\n\n```{bash}\n$ scancel [jobid]\n```\n\ninformation about the compute nodes:\n\n```{bash}\n$ sinfo -lNe\n```\n\nList the current status of the slurm queue:\n\n```{bash}\n$ squeue\n```\n\nFind information on previously completed jobs:\n\n```{bash}\n$ sacct\n```\n\nList information on running jobs:\n\n```{bash}\n$ sstat\n```\n\n::: {.greeting .message style=\"color: red;\"}\n## Constructing a slurm Job - good practice\n\nAdapt RNAseq processing script 1-QC.sh (see session Session5 -RNAseq-Processing) to run under slurm (do not run script 2 -- building genome) \\*\\* if you find this easy try adapting script 3,4 and 5.\n\nYou may want to discuss the resources required for the job.\n\nHints:\n\ndefine directories using full path derived with `PWD -P`\n\n```{bash}\n~/mydata/ = /mnt/clusters/sponsa/data/$USER/\n```\n\nWhen creating composite variables use enclose them in quotation marks to ensure they expand.\n\n```{bash}\n\"${indir}/fastq/${i}_1.fastq\"\n```\n:::\n\n## Interactive Jobs\n\nEnter an interactive job and use this to review the files created by the RNAseq processing scripts.\n\n```{bash}\n##Use any available node\nsrun -c 4 --mem=8G -p defq --pty bash\n\n##use a specific node - in this example called gomphus3\n\nsrun -c 4 --mem=8G -p defq --nodelist=gomphus3 --pty bash\n```\n\nRemember to exit the interactive job when you are finished by typing `exit`\n\n***Advanced:*** Some HPC architectures will allow you to directly write to the 'local' harddrive `/tmp` For jobs with lots of I/O and where the nodes are using new M2 SSD drives this can accelerate certain types of jobs.\n\n# Using HPC resources effectively\n\n::: {.greeting .message style=\"color: red;\"}\ngomphus.job_history.sh\n\n| User  | JobID | State     | Start              | End                 | AllocCPUS | TotalCPU  | CPUEf | ReqMem | axRSS    | MemEf | AveDiskRead | AveDiskWrite |\n|------|------|------|------|------|------|------|------|------|------|------|------|------|\n| smbpk | 7174  | COMPLETED | 2022-11-07T09:18:2 | 2022-11-07T09:23:13 | 4         | 05:25.029 | 27.9% | 32000M | 1776696K | 5.4%  | 20940.17M   | 6974.14M     |\n\n:::\n\n## blast as an example\n\nWe take a closer look at running jobs on our cluster, we should provide examples of benchmarking code in order to find how to best utilise the resources available.\n\nWe start off by benchmarking a simple blast job, initially running over a single core, then parallelizing the job using blast's built-in threading. All jobs are run on a single node, and we test a number of nodes and compare results. For example source code, see the folder `~/classdata/REFS/slurm/slurm_examples/indepth_parallelizing_blastp` on the gomphus server.\n\nRemember to run all commands in your `~/mydata/[directory]`.\n\nFirst we obtain the sample data:\n\n```{bash}\n# this is already downloaded to ~/classdata/REFS/slurm/slurm_examples/indepth_parallelizing_blastp/\ncurl -L -o TAIR10_pep.fasta  https://www.arabidopsis.org/download_files/Proteins/TAIR10_protein_lists/TAIR10_pep_20101214\n\n## we can prepare the data within a interactive job\nsrun -c 4 --mem=8G -p defq --pty bash\n\n## navigate to mydata directory\ncd ~/mydata/\n\n## make a dirctory for blast test\nmkdir -p blast_test && cd blast_test \n\n## copy TAIR file accross from class data to local file system\ncp /mnt/clusters/sponsa/data/classdata/Bioinformatics/REFS/slurm/slurm_examples/indepth_parallelizing_blastp/run2_split-files4/TAIR10_pep.fasta .\n\n## Makeblast db from downloaded file\nmodule load blast/2.12.0\nmakeblastdb -in TAIR10_pep.fasta -parse_seqids -dbtype prot -title \"Small protein database\" -out TAIR10_pep\n\n##copy the query sub-set\ncp /mnt/clusters/sponsa/data/classdata/Bioinformatics/REFS/slurm/slurm_examples/indepth_parallelizing_blastp/TAIR10_pep_4000.fasta .\n\nexit\n```\n\nNow create the job Script - blastp.sh\n\n```{bash}\n#!/bin/bash\n#SBATCH --partition=defq       # the requested queue\n#SBATCH --nodes=1              # number of nodes to use\n#SBATCH --tasks-per-node=1     # \n#SBATCH --cpus-per-task=1      #   \n#SBATCH --mem-per-cpu=92000     # in megabytes, unless unit explicitly stated\n#SBATCH --error=%J.err         # redirect stderr to this file\n#SBATCH --output=%J.out        # redirect stdout to this file\n##SBATCH --mail-user=[insert email address]@Cardiff.ac.uk  # email address used for event notification\n##SBATCH --mail-type=start                                 # email on job start  \n##SBATCH --mail-type=end                                   # email on job end\n##SBATCH --mail-type=fail                                  # email on job failure\n\necho \"Usable Environment Variables:\"\necho \"=============================\"\necho \\$SLURM_JOB_ID=${SLURM_JOB_ID} \necho \\$SLURM_NTASKS=${SLURM_NTASKS}\necho \\$SLURM_NTASKS_PER_NODE=${SLURM_NTASKS_PER_NODE}\necho \\$SLURM_CPUS_PER_TASK=${SLURM_CPUS_PER_TASK}\necho \\$SLURM_JOB_CPUS_PER_NODE=${SLURM_JOB_CPUS_PER_NODE}\necho \\$SLURM_MEM_PER_CPU=${SLURM_MEM_PER_CPU}\ncat $0\n\nmodule load blast/2.12.0\n\nindir=\"/mnt/clusters/sponsa/data/${USER}/blast_test\"\n\ndbdir=\"/mnt/clusters/sponsa/data/${USER}/blast_test\"\n\noutdir=\"/mnt/clusters/sponsa/data/${USER}/blast_test\"\n\ntime blastp -num_threads ${SLURM_CPUS_PER_TASK} \\\n            -query \"${indir}/TAIR10_pep_4000.fasta\" \\\n            -task blastp \\\n            -num_descriptions 16 \\\n            -num_alignments 1 \\\n            -db ${dbdir}/TAIR10_pep \\\n            -out \"${outdir}/blastp_cpu${SLURM_CPUS_PER_TASK}_job${SLURM_JOBID}.txt\"\n```\n\n::: {.greeting .message style=\"color: red;\"}\nRun this blast script a number of times, increasing the --cpus-per-task and decreasing the --mem-per-cpu variables accordingly (ie 2 cpus-per-task & 46000 mem-per-cpu, 3 cpus-per-task & 30600 mem-per-cpu .....16 cpus-per-task & 5750 mem-per-cpu. Review the benchmarks considering the resources needed and the time taken to execute the jobs\n\nWhat are your conclusions\n:::\n\n## Reviewing and optimising job resources\n\n::: {.greeting .message style=\"color: red;\"}\nUse `gomphus.job_history.sh` to review the efficiency of your job\n:::\n\n# Threads, MPI and embarrassingly parallel\n\n## Parallel Jobs\n\nThere are a number of different scenarios in which you may want to parallelize your job:\n\n-   Embarrassingly parallel\n-   MPI - a multi-process application (possibly across multiple compute hosts)\n-   multi-threading - shared memory using OpenMP or perhaps pthreads.\n-   multiple instances of a single application.\n-   ...plus more scenarios but are probably out of scope of this tutorial.\n\n## Embarrassingly parallel\n\nMany processes in genomics do the same task on large arrays of data. One of the simplest way of speeding up the process is to split up the input files and perfrom the same task multiple times at the same time - this is called an \\_**'Embarrassingly parallel'** task.\n\nLets do this for the blast example that we started in the last task. We can investigate whether there are any further methods of improving performance, and attempt to find a improvemet in the initial blast job's solution to reduce the time taken. As it turns out, it is possible in this situation to split the input fasta file into a number of sections, and have an independent job acting on each of those sections. Each independent job could then be parallelized, say over 8 threads, and all jobs can run concurrently.\n\nWe create a job script (mammoth_8thread_split_1of4.sh) that will run blast command on the first file-section only.\n\nWe perform the following sequence of commands, first splitting the input fasta file into 4 parts, then creating the 4 independent job-scripts, and submit the jobs.\n\n```{bash}\n## enter a interactive Job\nsrun -c 4 --mem=8G -p defq --pty bash\ncd ~/mydata/blast_test/\n\n## a new folder\nmkdir split-files4\ncd split-files4/\ncp ~/TAIR10_pep_4000.fasta  .\n#\n## split the fasta file into 4 equal(ish) sections\ncurl -L https://raw.githubusercontent.com/gmarnellos/Trinotate_example_supplement/master/split_fasta.pl | perl /dev/stdin  TAIR10_pep_4000.fasta  TAIR10_pep.vol 1000\n```\n\ncreate script that will spawn blast_jobs (use nano or vi) - spawn_blastp.sh\n\n```{bash}\n!#/bin/bash\n\nfor i in {1..4};do\n\nexport i\n\nsbatch blastp.sh\n\ndone\n```\n\nmake script executable `chmod +x spawn_blastp.sh`\n\nEdit blast job so that each time it is called it uses a different section of the query file\n\n```{bash}\n#!/bin/bash\n#SBATCH --partition=defq       # the requested queue\n#SBATCH --nodes=1              # number of nodes to use\n#SBATCH --tasks-per-node=1     # \n#SBATCH --cpus-per-task=8      #   \n#SBATCH --mem-per-cpu=11500    # in megabytes, unless unit explicitly stated\n#SBATCH --error=%J.err         # redirect stderr to this file\n#SBATCH --output=%J.out        # redirect stdout to this file\n##SBATCH --mail-user=[insert email address]@Cardiff.ac.uk  # email address used for event notification\n##SBATCH --mail-type=start                                 # email on job start  \n##SBATCH --mail-type=end                                   # email on job end\n##SBATCH --mail-type=fail                                  # email on job failure\n\necho \"Usable Environment Variables:\"\necho \"=============================\"\necho \"hostname=$(hostname)\"\necho \\$SLURM_JOB_ID=${SLURM_JOB_ID} \necho \\$SLURM_NTASKS=${SLURM_NTASKS}\necho \\$SLURM_NTASKS_PER_NODE=${SLURM_NTASKS_PER_NODE}\necho \\$SLURM_CPUS_PER_TASK=${SLURM_CPUS_PER_TASK}\necho \\$SLURM_JOB_CPUS_PER_NODE=${SLURM_JOB_CPUS_PER_NODE}\necho \\$SLURM_MEM_PER_CPU=${SLURM_MEM_PER_CPU}\n\ncat $0\n\nmodule load blast/2.12.0\n\nindir=\"/mnt/clusters/sponsa/data/${USER}/blast_test/split-files4\"\n\ndbdir=\"/mnt/clusters/sponsa/data/${USER}/blast_test\"\n\noutdir=\"/mnt/clusters/sponsa/data/${USER}/blast_test/split-files4\"\n\ntime blastp -num_threads ${SLURM_CPUS_PER_TASK} \\\n            -query \"${indir}/TAIR10_pep.vol.${i}.fasta\" \\\n            -task blastp \\\n            -num_descriptions 16 \\\n            -num_alignments 1 \\\n            -db ${dbdir}/TAIR10_pep \\\n            -out \"${outdir}/blastp_vol${i}_cpu${SLURM_CPUS_PER_TASK}_job${SLURM_JOBID}.txt\"\n```\n\nPerform file-splitting procedure for both a 2-split and a 4-split of the original fasta file. The 'time-to-solution' results are added to the original benchmark chart. We assume that all jobs run concurrently, and we take the wall-time for the longest job\n\n## MPI Jobs\n\nOur example MPI job is based on a quantum espresso calculation. This script utilises the srun command, which is part of the slurm family of tools to run a parallel job on a cluster\n\n```{bash}\n#!/bin/bash\n#SBATCH --partition=mammoth    # the requested queue\n#SBATCH --job-name=qe_mpi      # name the job           \n#SBATCH --nodes=1              # number of nodes to use\n#SBATCH --ntasks=32            # total number of tasks (processes)\n#SBATCH --mem-per-cpu=100      # in megabytes, unless unit explicitly stated\n#SBATCH --error=%J.err         # redirect stderr to this file\n#SBATCH --output=%J.out        # redirect stdout to this file\n##SBATCH --mail-user=[insert email address]@Cardiff.ac.uk  # email address used for event notification\n##SBATCH --mail-type=end                                   # email on job end\n##SBATCH --mail-type=fail                                  # email on job failure\n\nmodule load  qe/6.0\n\necho \"Usable Environment Variables:\"\necho \"=============================\"\necho \"hostname=$(hostname)\"\necho \\$SLURM_JOB_ID=${SLURM_JOB_ID}\necho \\$SLURM_NTASKS=${SLURM_NTASKS}\necho \\$SLURM_NTASKS_PER_NODE=${SLURM_NTASKS_PER_NODE}\necho \\$SLURM_CPUS_PER_TASK=${SLURM_CPUS_PER_TASK}\necho \\$SLURM_JOB_CPUS_PER_NODE=${SLURM_JOB_CPUS_PER_NODE}\necho \\$SLURM_MEM_PER_CPU=${SLURM_MEM_PER_CPU}\necho \"module list:\"\nmodule list 2>&1\n\n# Some of these environment variables are utilised by the qe executable itself\nexport ESPRESSO_DATAPATH=/mnt/clusters/sponsa/data/classdata/Bioinformatics/REFS/slurm/slurm_examples/example2_mpi/\nexport ESPRESSO_PSEUDO=${ESPRESSO_DATAPATH}\nexport ESPRESSO_TMPDIR=${ESPRESSO_DATAPATH}/${SLURM_JOB_ID}\n\n# handy to place this in job output for future reference...\ncat ${ESPRESSO_DATAPATH}/atom.in\n\n# execute the parallel job (we also time it)\ntime srun -n ${SLURM_NTASKS} pw.x < ${ESPRESSO_DATAPATH}/atom.in > atom.job${SLURM_JOB_ID}.out\n```\n\nThe job requests 32 cores to be allocated, and runs the srun command with the argument -n \\${SLURM_NTASKS} which tells srun to spawn the mpi-job with the total number of processes requested. Quantum Espresso utilises the environment variable ESPRESSO_TMPDIR which points to a temporary folder. We design this in our slurm script to point to a subfolder.\n\nAn alternative storage location is the compute node's local storage. This can improve runtime I/O performance. However, local storage on the compute nodes is limited (Gigabytes not Terabytes), and it's availability is a little hidden from the user, so take care not to fill up the disk(!) and remove all files from the compute node's local storage within the job script (your only access to the compute node's /local folder is via the slurm script). An alternative job script which utilises a compute node's /local storage is provided on the gomphus server /mnt/clusters/sponsa/data/classdata/Bioinformatics/REFS/slurm/slurm_examples/example2_mpi/example2_mpi_localstorage.sh.\n\n## Threaded Jobs\n\nA number of popular bioinformatics software are capable of parallelising execution using threads (usually OpenMP or pthreads). This parallelisation method does not normally use distributed memory, so the application will need to be run on a single node. Our threaded example slurm-script is based on BLAST+. The job script is listed:\n\n```{bash}\n#!/bin/bash\n#SBATCH --partition=defq\n#SBATCH --nodes=1\n#SBATCH --tasks-per-node=1\n#SBATCH --cpus-per-task=8\n#SBATCH --mem-per-cpu=2000\n#SBATCH --error=%J.err\n#SBATCH --output=%J.out\n##SBATCH --mail-type=end\n##SBATCH --mail-user=[your.email@address]\n\n\n# Example slurm script\n#  This script is a little wasteful of resources,\n#  but demonstrates a simple pipeline.\n#  \n#  For a more efficient use of resources, please consider\n#  running the pipeline as a series of jobs (chain-jobs).\n\n\necho \"Usable Environment Variables:\"\necho \"=============================\"\necho \"hostname=$(hostname)\"\necho \\$SLURM_JOB_ID=${SLURM_JOB_ID}\necho \\$SLURM_NTASKS=${SLURM_NTASKS}\necho \\$SLURM_NTASKS_PER_NODE=${SLURM_NTASKS_PER_NODE}\necho \\$SLURM_CPUS_PER_TASK=${SLURM_CPUS_PER_TASK}\necho \\$SLURM_JOB_CPUS_PER_NODE=${SLURM_JOB_CPUS_PER_NODE}\necho \\$SLURM_MEM_PER_CPU=${SLURM_MEM_PER_CPU}\necho \"module list:\"\nmodule list 2>&1\n\nDATAFOLDER=/mnt/clusters/sponsa/data/classdata/Bioinformatics/REFS/slurm/slurm_examples/example3_pipeline\n\n\n### The data used in this pipeline has already been downloaded and stored in $DATAFOLDER.\n### Here are the commands used to download the data...\n# cd $DATAFOLDER\n# curl -LO https://data.broadinstitute.org/Trinity/Trinotate_v2.0_RESOURCES/uniprot_sprot.trinotate_v2.0.pep.gz\n# gunzip uniprot_sprot.trinotate_v2.0.pep.gz\n# curl -LO https://data.broadinstitute.org/Trinity/Trinotate_v2.0_RESOURCES/Pfam-A.hmm.gz\n# gunzip Pfam-A.hmm.gz\n# curl -L -o Trinotate.sqlite.gz https://data.broadinstitute.org/Trinity/Trinotate_v2.0_RESOURCES/Trinotate.sprot_uniref90.20150131.boilerplate.sqlite.gz\n# gunzip Trinotate.sqlite.gz\n# curl -LO ftp://ftp.ensembl.org/pub/release-82/fasta/mus_musculus/cdna/Mus_musculus.GRCm38.cdna.all.fa.gz\n# gunzip Mus_musculus.GRCm38.cdna.all.fa.gz\n# curl -LOgz https://github.com/gmarnellos/Trinotate_example_supplement/raw/master/mouse38_cdna.fa.gz\n# gunzip mouse38_cdna.fa.gz\n\n# Now we get on to the pipeline\n\n# make a link to all datafiles\nfor f in ${DATAFOLDER}/* ; do ln -s $f ; done\n\n#Index the SwissProt database for use with blast\n\nmodule load blast\nmakeblastdb -version\nmakeblastdb -in uniprot_sprot.trinotate_v2.0.pep -dbtype prot\nmodule unload blast\n\n# Prepare the Pfam database for use with hmmscan\nmodule load hmmer\nhmmpress -h\nhmmpress Pfam-A.hmm\nmodule load hmmer\n\n# Use Transdecoder to produce the most likely longest-ORF peptide candidates\nmodule load TransDecoder/v3.0.1\nTransDecoder.LongOrfs -t mouse38_cdna.fa\nTransDecoder.Predict -t mouse38_cdna.fa\nmodule unload TransDecoder/v3.0.1\n\nmodule load blast\nblastx -query mouse38_cdna.fa -db uniprot_sprot.trinotate.pep -num_threads ${SLURM_CPUS_PER_TASK} -max_target_seqs 1 -outfmt 6 > blastx.vol.outfmt6\nblastp -query mouse38_cdna.fa.transdecoder.pep -db uniprot_sprot.trinotate_v2.0.pep -num_threads ${SLURM_CPUS_PER_TASK} -max_target_seqs 1 -outfmt 6 > blastp.vol.outfmt6\nmodule unload blast\n\n# Identify protein domains\nmodule load hmmer/3.1b2\nhmmscan --cpu ${SLURM_CPUS_PER_TASK} --domtblout TrinotatePFAM.out Pfam-A.hmm mouse38_cdna.fa.transdecoder.pep > pfam.log\nmodule unload hmmer/3.1b2\n\n# Produce the Gene/Transcript relationship\ngrep \"^>\" Mus_musculus.GRCm38.cdna.all.fa   | perl -p -e 's/^>(\\S+).*\\s+gene:(ENSMUSG\\d+).*$/$2\\t$1/' > gene_transcript_map.txt\n\n# Now populate the sqlite database\nmodule load Trinotate/v3.0.1\nTrinotate Trinotate.sqlite init --gene_trans_map gene_transcript_map.txt --transcript_fasta mouse38_cdna.fa --transdecoder_pep mouse38_cdna.fa.transdecoder.pep\nTrinotate Trinotate.sqlite LOAD_swissprot_blastp blastp.vol.outfmt6\nTrinotate Trinotate.sqlite LOAD_swissprot_blastx blastx.vol.outfmt6\nTrinotate Trinotate.sqlite LOAD_pfam TrinotatePFAM.out\n# Create the annotation report\nTrinotate Trinotate.sqlite report -E 0.00001 > trinotate_annotation_report.xls\nmodule unload Trinotate/v3.0.1\n```\n\nThis is quite a busy job-script (and also inefficient on resources!). It runs through a number of steps, but some of those steps will utilise parallelisation via threading, and use the slurm environment variable SLURM_CPUS_PER_TASK to inform the application(s) of the correct number of threads.\n\nBut why is this job inefficient on resources? This particular job involves a number of steps: some utilising parallelisation, and some not; some memory-hungry, others not. The problem with this is that the job has allocated to it a set amount of resources (compute and memory), which is allocated to it for the lifetime of the job. But only at certain times in this job are the resources requested fully utilised. At all other times this job is running, the resources are allocated, but not used, and therefore making those resources unavailable to other jobs. This has a knock-on effect of increasing queue-times, and leaves expensive resources idle.\n\nA much more efficient way of running the same pipeline is to chain the job - split the pipeline into component parts and submit separate jobs for each of those parts. Each section of the pipeline (having its own job-script) is then free to allocate resources specific to that section of the pipeline. In the slurm world this is called job chaining, and has been exemplified in the next section using the same pipeline.\n\n## Job Chains and Job Dependency\n\nChaining jobs is a method of sequentially running dependent jobs. Our chain-job example is a pipeline of 6 separate job scripts, based on the blast+ pipeline of the previous section. We do not show the full six job-scripts here for brevity, but are available on the gomphus cluster under /mnt/clusters/sponsa/data/classdata/Bioinformatics/REFS/slurm/slurm_examples/example4_chain.\n\nSlurm has an option -d or --dependency that allows to specify that a job is only permitted to start if another job finished successfully.\n\nIn the folder (gomphus cluster) /mnt/clusters/sponsa/data/classdata/Bioinformatics/REFS/slurm/slurm_examples/example4_chain there are 6 separate job-scripts that need to be executed in a certain order. They are numbered in the correct pipeline order:\n\n```{bash}\n[user@gomphus ~]$ tree  /mnt/clusters/sponsa/data/classdata/Bioinformatics/REFS/slurm/slurm_examples/example4_chain\n/mnt/clusters/sponsa/data/classdata/Bioinformatics/REFS/slurm/slurm_examples/example4_chain\nâ”œâ”€â”€ example4_chain-step1.sh\nâ”œâ”€â”€ example4_chain-step2.sh\nâ”œâ”€â”€ example4_chain-step3.sh\nâ”œâ”€â”€ example4_chain-step4.sh\nâ”œâ”€â”€ example4_chain-step5.sh\nâ”œâ”€â”€ example4_chain-step6.sh\nâ”œâ”€â”€ example4_submit_all.sh\nâ”œâ”€â”€ mouse38_cdna.fa\nâ”œâ”€â”€ Mus_musculus.GRCm38.cdna.all.fa\nâ”œâ”€â”€ Pfam-A.hmm\nâ”œâ”€â”€ pipeline1.sh\nâ”œâ”€â”€ Trinotate.sqlite\nâ””â”€â”€ uniprot_sprot.trinotate_v2.0.pep\n\n0 directories, 13 files\n```\n\nEach job is (importantly) commonly named using #SBATCH --job-name within each job-script. Also within this folder is a simple script (example4_submit_all.sh) that will execute the sbatch command on each of the job-scripts in the correct order:\n\n```{bash}\n#!/bin/bash:\n\nfor c in /mnt/clusters/sponsa/data/classdata/Bioinformatics/REFS/slurm/slurm_examples/example4_chain/example4_chain-step?.sh ;\ndo\n sbatch -d singleton $c\ndone\n```\n\nThis sbatch command uses the -d singleton flag to notify slurm of the job-dependencies (all jobs must have the name job name defined by `#SBATCH --job-name [some constant name]`. At which point each submitted job will be forced to depend on successful completion of any previous job submitted by the same user, and with the same job-name. The full pipeline of 6 jobs will now run to completion, with no further user-intervention, making efficient use of the available resources.\n"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"knitr"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","css":["styles.css"],"toc":true,"output-file":"2.1_HPC_Cloud_Slurm.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","appendix-view-license":"View License","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","tools-share":"Share","tools-download":"Download","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words","listing-page-filter":"Filter","draft":"Draft"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.6.39","editor":"visual","theme":"cosmo","title-block-style":"default","title-block-banner":"darkred","title-block-banner-color":"white","title":"HPC, Cloud Computing & Job Schedulers","subtitle":"High Performace Computing","author":"Prof. Peter Kille","date":"today","affiliation":"Cardiff University"},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}